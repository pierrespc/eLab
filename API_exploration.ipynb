{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d4baa64",
   "metadata": {},
   "source": [
    "# API Functions to import/export/update eLab\n",
    "\n",
    "Here we will provide some examples of API functionalities with case examples\n",
    "\n",
    "## Configuration of eLab API and Google Drive API\n",
    "To install google-api to be able to query the table, see https://medium.com/swlh/google-drive-api-with-python-part-i-set-up-credentials-1f729cb0372b.\n",
    "\n",
    "Then to use it, you may be interested in that help: https://billydharmawan.medium.com/?p=e8c7b4b79f39\n",
    "\n",
    "Note that the actions to create the credentials.json file below do not work from jupyter. Just open a python shell and copy-paste them! Once this done, the code below works.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ac0bae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import csv\n",
    "import pandas\n",
    "import numpy\n",
    "from apiclient import discovery, errors\n",
    "from httplib2 import Http\n",
    "from oauth2client import client, file, tools\n",
    "import os.path\n",
    "\n",
    "token = format(open(\"credentials/tokenELAB\",\"r\").readline().strip())\n",
    "url = \"https://elab-dev.pasteur.fr/api/v1/\"\n",
    "headers1 = {'Authorization': token, 'Accept': 'application/json','Content-Type':'application/json'}\n",
    "headers2 = {'Authorization': token, 'Accept': 'application/json'}\n",
    "params={}\n",
    "\n",
    "\n",
    "credentials_file_path = './credentials/credentials.json'\n",
    "clientsecret_file_path = './credentials/client_secret.json'\n",
    "#print(os.path.isfile(clientsecret_file_path ))\n",
    "#print(os.path.isfile(credentials_file_path ))\n",
    "SCOPE = 'https://www.googleapis.com/auth/drive'\n",
    "\n",
    "store = file.Storage(credentials_file_path)\n",
    "credentials=store.get()\n",
    "if not credentials or credentials.invalid:\n",
    "    flow =  client.flow_from_clientsecrets(clientsecret_file_path, SCOPE)\n",
    "    print(flow.client_id)\n",
    "    credentials =  tools.run_flow(flow, store)\n",
    "\n",
    "http = credentials.authorize(Http())\n",
    "drive = discovery.build('drive','v3',http=http)\n",
    "sheets = discovery.build('sheets', 'v4', credentials=credentials)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fa2163",
   "metadata": {},
   "source": [
    "## Class Definition\n",
    "Here we define classes for experiments, sample types etc\n",
    "\n",
    "### Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8c0a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(url + \"experiments\", headers = headers2,params = params)\n",
    "data = r.json()\n",
    "experiments = {}\n",
    "for exp in data.get(\"data\"):\n",
    "    experiments[format(exp.get(\"name\"))] = format(exp.get(\"experimentID\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5f7a2d",
   "metadata": {},
   "source": [
    "### Projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a5ee33",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(url + \"projects\", headers = headers2,params = params)\n",
    "data = r.json()\n",
    "projects = {}\n",
    "for pro in data.get(\"data\"):\n",
    "    projects[format(pro.get(\"name\"))] = format(pro.get(\"projectID\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad1ed46",
   "metadata": {},
   "source": [
    "### Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe10142",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(url + \"storage\", headers = headers2)\n",
    "data = r.json()\n",
    "storage = {}\n",
    "for sto in data.get(\"data\"):\n",
    "    storage[format(sto.get(\"name\"))] = format(sto.get(\"storageID\"))\n",
    "    if sto.get(\"name\") == \"Freezer n9\":\n",
    "        print(sto)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ee2571",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sto)\n",
    "print(storage)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79b0e97",
   "metadata": {},
   "source": [
    "## Obtain classes for each all samples types "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa5aeac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r = requests.get(url + \"sampleTypes\", headers = headers2)\n",
    "data = r.json()\n",
    "#types = []\n",
    "#for typ in data.get(\"data\"):\n",
    "#    types.append({format(typ.get(\"name\")):format(typ.get(\"sampleTypeID\"))})\n",
    "types = {}\n",
    "for typ in data.get(\"data\"):\n",
    "    types[format(typ.get(\"name\"))] = format(typ.get(\"sampleTypeID\"))\n",
    "\n",
    "print(types)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2857e69b",
   "metadata": {},
   "source": [
    "## Obtain the list of samples for each sample type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9455c444",
   "metadata": {},
   "outputs": [],
   "source": [
    "registered = {}\n",
    "for it in types.items():\n",
    "    name = it[0]\n",
    "    ID = it[1]\n",
    "    #print(name + \" --> \" + ID)\n",
    "    r = requests.get(url + \"samples\" , headers = headers2, params = {'sampleTypeID': ID})\n",
    "    data = r.json()\n",
    "    myList = {}\n",
    "    for sam in data.get(\"data\"):\n",
    "        if format(sam.get(\"name\")) in myList.keys():\n",
    "            print(name + \": \" + sam.get(\"name\") + \" duplicated\")\n",
    "            break\n",
    "        myList[format(sam.get(\"name\"))]=format(sam.get(\"sampleID\"))\n",
    "    registered[name] = myList\n",
    "    \n",
    "print(registered[\"Individual\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b822b99",
   "metadata": {},
   "source": [
    "## Upload samples to eLab\n",
    "\n",
    "### Define a dictionnary for feature names in eLab and in our tables\n",
    "One dictionary for each sample type.\n",
    "Note that \"parent sample\" is not a pre-set feature so it does not appear."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6ac771",
   "metadata": {},
   "source": [
    "#### Get the columns corresponding to eLab features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3df1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "SiteDict={\n",
    "    \"Name\":\"Site\",\n",
    "    \"Description\":\"None\",\n",
    "    \"Note\":\"None\",\n",
    "    \"Amount\":\"fixed_1\",\n",
    "    \"Unit\":\"fixed_unit\",\n",
    "    \"Main geographic region\":\"Geographic Zone\",\n",
    "    \"Country\":\"Country\",\n",
    "    \"Province / Region\":\"Province / Region\",\n",
    "    \"Locality\":\"Locality\",\n",
    "    \"Latitude\":\"LatChanged\",\n",
    "    \"Longitude\":\"LongChanged\",\n",
    "    \"Site type\":\"Site type\",\n",
    "    \"Pictures\":\"None\"\n",
    "}\n",
    "\n",
    "IndDict={\n",
    "    \"Name\":\"RascovanLabID\",\n",
    "    \"Description\":\"None\",\n",
    "    \"Note\":\"None\",\n",
    "    \"Amount\":\"fixed_1\",\n",
    "    #\"Unit\":\"fixed_Unit | pcs\",\n",
    "    \"Unit\":\"fixed_unit\",\n",
    "    \"parentSampleID\":\"Site\",\n",
    "    \"Archaeologist ID\":\"Individual ID\",\n",
    "    \"Archaeologist group\":\"Archaeologists Group\",\n",
    "    \"Site Name\":\"Site\",\n",
    "    \"Date\":\"Date\",\n",
    "    \"Datation method\":\"Datation Method\",\n",
    "    #\"Subsistence Strategy\": \"Subsistence.Strategy\",\n",
    "    \"Age\":\"Age\",\n",
    "    \"Gender\":\"Gender\",\n",
    "    \"Pictures\":\"None\",\n",
    "    \"Linked individuals\":\"None\"\n",
    "}\n",
    "\n",
    "SkeDict={\"Name\":\"RascovanLabID\",\n",
    "         \"From Individual\":\"RascovanLabID\",\n",
    "         \"Description\":\"Observations\",\n",
    "         \"Note\":\"None\",\n",
    "         \"Amount\":\"fixed_1\",\n",
    "         #\"Unit\":\"fixed_Unit | pcs\",\n",
    "         \"Unit\":\"fixed_unit\",\n",
    "         \"parentSampleID\":\"TobeextractFromRascovanLabID\",\n",
    "         \"Archaeologist sample ID\":\"Sample ID\",\n",
    "         \"Pictures Labelling\":\"PicturePath\",\n",
    "         \"Bone type\":\"Bone Type\",\n",
    "         \"Skeleton element\":\"Skeletal Element\",\n",
    "         \"Exportation Permit Number\":\"Expediente\",\n",
    "         \"Observation Labelling\":\"Observation Pierre / Maria\",\n",
    "         \"Observation Drilling\":\"GeneralSampleComment\",\n",
    "         \"Pictures Drilling\":\"DrillingPictures\"\n",
    "}\n",
    "\n",
    "ExeDict={\"Name\":\"ExtractID\",\n",
    "         \"From Skeleton Element\":\"RascovanLabID\",\n",
    "         \"Description\":\"None\",\n",
    "         \"Note\":\"None\",\n",
    "         \"Amount\":\"Weight\",\n",
    "         \"Unit\":\"fixed_gram\",\n",
    "         \"parentSampleID\":\"RascovanLabID\",\n",
    "         \"Date of drilling\":\"Date\",\n",
    "         \"Pictures\":\"None\",\n",
    "         \"Person in charge\":\"fixed_Maria Lopopolo\",\n",
    "         \"Laboratory where processed\":\"fixed_Hannes Schroeder\",\n",
    "         \"Extract Type\":\"ExtractType\",\n",
    "         \"Conservation\":\"Observation\",\n",
    "         \"Pathology\":\"Pathologie\",\n",
    "         \"Pathology description\":\"None\",\n",
    "         \"Taken for extraction\":\"TakenForExtraction\",\n",
    "         \"Extracted\":\"Extraction\",\n",
    "         \"Extraction Comment\":\"extractionComment\",\n",
    "         \"density UDG treatment (ng/uL)\":\"densityUDGtreated\",\n",
    "         \"Volume UDG treatment (uL)\":\"volumeUDGtreated\",\n",
    "         \"mass UDG in Tube (ng)\":\"massInTube\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ad1ce6",
   "metadata": {},
   "source": [
    "### For \"macro\" sample types (Site, Individual, Skeleton Element)\n",
    "\n",
    "We start from a tsv file (downloaded from there: https://docs.google.com/spreadsheets/d/1bnu9oZV5fXOaPY_KDvBEBSIIzbydPxyWdLg-A83cJnc/edit#gid=159434896 and then formatted through a Rscript...). (I will figure out how to download it automatically later), and then we register the site one by one. If a site exists in eLab, we change (patch) the values, if not we register it from scratch.\n",
    "\n",
    "To install google-api to be able to query the table, see https://medium.com/swlh/google-drive-api-with-python-part-i-set-up-credentials-1f729cb0372b.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1548d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_token = None\n",
    "driveFiles=[]\n",
    "while True:\n",
    "    try:\n",
    "        param = {}\n",
    "        if page_token:\n",
    "            param['pageToken'] = page_token\n",
    "        files = drive.files().list(**param).execute()\n",
    "        # append the files from the current result page to our list\n",
    "        driveFiles.extend(files.get('files'))\n",
    "        # Google Drive API shows our files in multiple pages when the number of files exceed 100\n",
    "        page_token = files.get('nextPageToken')\n",
    "        if not page_token:\n",
    "            break\n",
    "    except errors.HttpError as error:\n",
    "        print(f'An error has occurred: {error}')\n",
    "        break    # output the file metadata to console\n",
    "\n",
    "\n",
    "# define a function to export sheet to csv\n",
    "def download_sheet_to_csv(spreadsheet_id, sheet_name):\n",
    "    result = sheets.spreadsheets().values().get(spreadsheetId=spreadsheet_id, range=sheet_name).execute()\n",
    "    output_file = f'{sheet_name}.tsv'\n",
    "\n",
    "    with open(output_file, 'w') as f:\n",
    "        writer = csv.writer(f,delimiter=\"\\t\")\n",
    "        writer.writerows(result.get('values'))\n",
    "\n",
    "    f.close()\n",
    "\n",
    "    print(f'Successfully downloaded {sheet_name}.tsv')        \n",
    "        \n",
    "        \n",
    "        \n",
    "for file in driveFiles:\n",
    "    if file.get('name') == \"Conjuntos_Muestras_aDNA\":\n",
    "        id=file.get('id')\n",
    "        sheet='WholeDataSet'\n",
    "        download_sheet_to_csv(id,sheet)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8db484d",
   "metadata": {},
   "source": [
    "Now read the table and format it!\n",
    "\n",
    "WATCHOUT! There are many things that will need some tuning as we add entries in the google spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89b74b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawTab=pandas.read_csv(\"WholeDataSet.tsv\",delimiter=\"\\t\")\n",
    "rawTab=rawTab.dropna(subset=['RascovanLabID'])\n",
    "rawTab.loc[rawTab['Latitude'].isnull(),\"Latitude\"]=None\n",
    "rawTab.loc[rawTab['Longitud'].isnull(),\"Longitud\"]=None\n",
    "rawTab.loc[rawTab['Latitude'].isin([ \"Undefined\",\"desconocido\",\"nan\"]),\"Latitude\"]=None\n",
    "rawTab.loc[rawTab['Longitud'].isin([ \"Undefined\",\"desconocido\",\"nan\"]),\"Longitud\"]=None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33166d49",
   "metadata": {},
   "source": [
    "Change the coordinates so they are numerical (case by case here...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8554fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "###change coordinates\n",
    "def changeCOORfunction(coord):\n",
    "    stuf=\"º\"\n",
    "    stuf2=\"°\"\n",
    "    if coord is None:\n",
    "        #return([None,None,None,None])\n",
    "        return(None)\n",
    "\n",
    "    coordFed=coord\n",
    "    #print(coord)\n",
    "    #####HERE CHANGE ALL WEIRD CHARACTERS THAT CAN COME ON THE WAY\n",
    "    coord=coord.replace(\"39° 06 ́\",\"39°06'\")\n",
    "    coord=coord.replace(\"63° 47 ́\",\"63°47'\") \n",
    "    ##change weird degrees characters\n",
    "    coord=coord.replace(stuf2,stuf)\n",
    "    ##change weird minutes characters\n",
    "    coord=coord.replace(\"``\",\"\\\"\")\n",
    "    coord=coord.replace(\"´´\",\"\\\"\")\n",
    "    coord=coord.replace(\"”\",\"\\\"\")\n",
    "    coord=coord.replace(\"''\",\"\\\"\")\n",
    "    coord=coord.replace(\"’’\",\"\\\"\")\n",
    "    coord=coord.replace(\"“\",\"\\\"\")\n",
    "    ##change weird seconds characters\n",
    "    coord=coord.replace(\" ´\",\"'\")\n",
    "    coord=coord.replace(\"`\",\"'\")\n",
    "    coord=coord.replace(\"´\",\"'\")\n",
    "    coord=coord.replace(\"’\",\"'\")\n",
    "    ###we now that it is all South and West\n",
    "    coord=coord.replace(\" \",\"\")\n",
    "    coord=coord.replace(\"S\",\"\")\n",
    "    coord=coord.replace(\"O\",\"\")\n",
    "    coord=coord.replace(\"W\",\"\")\n",
    "    ###change decimal character\n",
    "    coord=coord.replace(\",\",\".\")\n",
    "\n",
    "    ##read degrees\n",
    "    if len(coord.split(stuf)) ==2 :\n",
    "        if coord.split(stuf)[1] == \"\":\n",
    "            if stuf not in coord:\n",
    "                coord=coord + stuf + \"0'\"\n",
    "            else:\n",
    "                coord=coord+\"0'\"\n",
    "    elif len(coord.split(stuf)) == 1 :\n",
    "        if stuf not in coord:\n",
    "            coord=coord + stuf + \"0'\"\n",
    "        else:\n",
    "            coord=coord+\"0'\"\n",
    "    else:\n",
    "        print(\"splitting minute/second \" + coordFed + \"-->\" + coord)\n",
    "            \n",
    "    deg=coord.split(stuf)[0]\n",
    "    ###read minutes and seconds\n",
    "    tmp=coord.split(stuf)[1]\n",
    "    minute=tmp.split(\"'\")[0]\n",
    "    if len(tmp.split(\"'\")) != 2:\n",
    "        print( coord.split(stuf))\n",
    "        print(\"splitting minute/second \" + coordFed + \"-->\" + coord)\n",
    "        raise()\n",
    "    else:\n",
    "        if tmp.split(\"'\")[1] == \"\":\n",
    "            sec=0\n",
    "        else:\n",
    "            sec=tmp.split(\"'\")[1]\n",
    "            sec=sec.replace(\"\\\"\",\"\")\n",
    "\n",
    "    #print([coordFed,coord,deg,minute,sec])\n",
    "    ####verify all read ok!\n",
    "    if numpy.isnan(float(deg)):\n",
    "        print(\"pb numerical degree\" + coordFed + \"-->\" +coord + \" (\" + deg + \")\")\n",
    "        raise()\n",
    "    if numpy.isnan(float(minute)):\n",
    "        print(minute)\n",
    "        print(\"pb numerical minute\" + coordFed + \"-->\" +coord + \" (\" + minute + \")\")\n",
    "        raise()\n",
    "    if numpy.isnan(float(sec)):\n",
    "        print(sec)\n",
    "        print(\"pb numerical sec\" + coordFed + \"-->\" + coord + \" (\" + sec + \")\")\n",
    "        raise()\n",
    "  \n",
    "    deg=float(deg)\n",
    "    minute=float(minute)\n",
    "    sec=float(sec)\n",
    "    new=deg+minute/60+sec/3600\n",
    "    #return([-new,deg,minute,sec])\n",
    "    return(-new)\n",
    "\n",
    "\n",
    "\n",
    "#print(rawTab.loc[rawTab['Latitude']==\"\"])\n",
    "rawTab['LatChanged']=rawTab['Latitude'].apply(changeCOORfunction)\n",
    "rawTab['LongChanged']=rawTab['Longitud'].apply(changeCOORfunction)\n",
    "\n",
    "print(rawTab[[\"LatChanged\",\"LongChanged\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc73b39c",
   "metadata": {},
   "source": [
    "\n",
    "Make Bone Type variable according to Skeletal Element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d66b0b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "l1=list(range(1,9)) * 8\n",
    "l2=list(itertools.chain.from_iterable(itertools.repeat(x, 8) for x in list(range(1,9))))\n",
    "l3=[]\n",
    "for i in list(range(0,len(l1))):\n",
    "    l3.append(str(l1[i])+\".\"+str(l2[i]))\n",
    "\n",
    "    \n",
    "toothElements=[\"tooth\",\n",
    "               \"diente\",\n",
    "               \"molar\",\n",
    "               \"mx\",\n",
    "               \"42 inf. 1° derecho\",\n",
    "               \" m \",\n",
    "               \" md\",\n",
    "               \"incisive\",\n",
    "               \"incisivo\",\n",
    "               \"incisor\",\n",
    "               \"canino\",\n",
    "               \"canine\",\n",
    "               l3,\n",
    "               \"1.1 o 2.1\",\n",
    "               \"1.5 o 2.5\"]\n",
    "\n",
    "calculusElements=[\"calculus\"]\n",
    "petrousElements=[\"petrous\",\n",
    "                 \"petroso\",\n",
    "                 \"petrozo\"]\n",
    "\n",
    "undefinedElements=[\"??\"]\n",
    "otherElements=[\"rib\",\n",
    "               \"fibula\",\n",
    "               \"matoideo\",\n",
    "               \"metatarsal\",\n",
    "               \"humer\",\n",
    "               \"humerus\",\n",
    "               \"lumbar\",\n",
    "               \"craneo\",\n",
    "               \"vertebra\",\n",
    "               \"tibia\",\n",
    "               \"radio\",\n",
    "               \"phalanx\",\n",
    "               \"phalange\",\n",
    "               \"longbone\",\n",
    "               \"femur\",\n",
    "               \"metacarpo\",\n",
    "               \"metatarsus\",\n",
    "               \"tarseano\",\n",
    "               \"hueso\",\n",
    "               \"femur\",\n",
    "              \"tarso\"]\n",
    "\n",
    "noHumanElements=[\"valva\"]    \n",
    "    \n",
    "    \n",
    "rawTab[\"Bone Type\"]=None\n",
    "for index, ele in rawTab[\"Skeletal Element\"].items():\n",
    "    lowerEle=ele.lower()\n",
    "    if bool([ttt for ttt in toothElements if(lowerEle in ttt or str(ttt) in lowerEle)]):\n",
    "        rawTab.at[index,\"Bone Type\"]=\"Tooth\"        \n",
    "    elif bool([ttt for ttt in calculusElements if(lowerEle in ttt or str(ttt) in lowerEle)]):\n",
    "        rawTab.at[index,\"Bone Type\"]=\"Dental Calculus\"\n",
    "    elif bool([ttt for ttt in petrousElements if(lowerEle in ttt or str(ttt) in lowerEle)]):\n",
    "        rawTab.at[index,\"Bone Type\"]=\"Petrous\"\n",
    "    elif bool([ttt for ttt in otherElements if(lowerEle in ttt or str(ttt) in lowerEle)]):\n",
    "        rawTab.at[index,\"Bone Type\"]=\"Other Bone\"\n",
    "    elif bool([ttt for ttt in undefinedElements if(lowerEle in ttt or str(ttt) in lowerEle)]):\n",
    "        rawTab.at[index,\"Bone Type\"]=\"Undefined\"\n",
    "    elif bool([ttt for ttt in noHumanElements if(lowerEle in ttt or str(ttt) in lowerEle)]):\n",
    "        rawTab.at[index,\"Bone Type\"]=\"non Human\"\n",
    "    else:\n",
    "        print(ele+\" issue...\")\n",
    "        \n",
    "        break\n",
    "    \n",
    "\n",
    "###check it is fine...\n",
    "for i in list(set(rawTab[\"Bone Type\"])):\n",
    "    print(i)\n",
    "    print(list(set(rawTab.loc[rawTab[\"Bone Type\"]==i][\"Skeletal Element\"])))\n",
    "\n",
    "if any(rawTab[\"Bone Type\"].isnull()):\n",
    "    print(\"HHAAAAAAA\")\n",
    "    print(rawTab.loc[rawTab[\"Bone Type\"].isnull()][\"Skeletal Element\"])\n",
    "    print(rawTab.loc[rawTab[\"Bone Type\"].isnull()])\n",
    "                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b436daa3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###back up\n",
    "table=rawTab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f44ce16",
   "metadata": {},
   "source": [
    "#### Prepare json for uploading and updating Sites \n",
    "\n",
    "Get features for Site "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a861fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(url + \"sampleTypes/\" + types[\"Site\"] + \"/meta\", headers = headers2)\n",
    "data = r.json()\n",
    "FeateLabSites = {}\n",
    "for feat in ['Name','Description','Note','Amount','Unit']:\n",
    "    FeateLabSites[feat] = {\"ID\": \"notMeta\"}\n",
    "for feat in data.get(\"data\"):\n",
    "    FeateLabSites[format(feat.get(\"key\"))] = { \"ID\":format(feat.get(\"sampleTypeMetaID\")),\n",
    "                                              \"TYPE\":format(feat.get(\"sampleDataType\"))}\n",
    "#print(FeateLabSites)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f4976e",
   "metadata": {},
   "source": [
    "And check that they have been declared SiteDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63064afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in FeateLabSites.keys():\n",
    "    if feat not in SiteDict.keys():\n",
    "        print(feat + \"--> NOT IN DICTIONARY\")\n",
    "        \n",
    "for feat in SiteDict.keys():\n",
    "    if feat not in FeateLabSites.keys():\n",
    "        print(feat + \"--> NOT IN eLAB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf594f7",
   "metadata": {},
   "source": [
    "Now, we make a table with unique entries for the relevant Columns for Sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d00230",
   "metadata": {},
   "outputs": [],
   "source": [
    "tableSite=pandas.DataFrame()\n",
    "for col in list(SiteDict.keys()):\n",
    "#        if SiteDict[col] == \"None\":\n",
    "        if SiteDict[col] == \"None\" or SiteDict[col].startswith(\"fixed\"):\n",
    "            continue\n",
    "#        elif SiteDict[col].startswith(\"fixed\"):\n",
    "#            tableSite[col]=SiteDict[col].split(\"_\")[1]\n",
    "        else:\n",
    "            tableSite[col]=table[ SiteDict[col]]\n",
    "tableSite=tableSite.drop_duplicates()\n",
    "print(tableSite)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecf174f",
   "metadata": {},
   "source": [
    "Now, remove entries for which no Site is reported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03e462d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(table[ table[SiteDict['Name']].isnull()][[IndDict['Name'],IndDict['Archaeologist ID']]])\n",
    "tableSite=tableSite.drop(tableSite[tableSite['Name'].isnull()].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce095fc0",
   "metadata": {},
   "source": [
    "Now, we check if there no Site name duplicates in that table (dropping Latitude and longitude because sometimes we have the exact location for each sample, in that case we will make a rough average location of the site)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8c7b3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(tableSite.drop(['Latitude','Longitude'],axis=1))\n",
    "duplicatedSites=tableSite.drop(['Latitude','Longitude'],axis=1)\n",
    "duplicatedSites=duplicatedSites.drop_duplicates()\n",
    "duplicatedSites=duplicatedSites[duplicatedSites['Name'].duplicated(keep=False)]\n",
    "if len(duplicatedSites.index) > 0 :\n",
    "    print(\"DUPLICATED SITES... GO BACK TO THE TABLE AND FIX THOSE\")\n",
    "    print(duplicatedSites.sort_values('Name'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146e6200",
   "metadata": {},
   "source": [
    "Now, we average Latitude and Longitude for each Site and check no further duplicated Site appears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f44fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "for si in list(tableSite['Name']):\n",
    "    if(len(tableSite.loc[tableSite['Name']==si,].index))>1:\n",
    "        for coor in ['Latitude','Longitude']:\n",
    "            tableSite.loc[tableSite['Name']==si,[coor]]=tableSite.loc[tableSite['Name']==si][coor].mean()\n",
    "            \n",
    "tableSite=tableSite.drop_duplicates()\n",
    "duplicatedSites=tableSite[tableSite['Name'].duplicated(keep=False)]\n",
    "if len(duplicatedSites.index) > 0 :\n",
    "    print(\"DUPLICATED SITES... GO BACK TO THE TABLE AND FIX THOSE\")\n",
    "    duplicatedSites.sort_values('Name')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d28a6f",
   "metadata": {},
   "source": [
    "Now match the number of digits handled by eLab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b59c59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tableSite['Latitude']=tableSite['Latitude'].round(12)\n",
    "tableSite['Longitude']=tableSite['Longitude'].round(12)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fe249a",
   "metadata": {},
   "source": [
    "We get all the possible values for checkboxes and dropdown features of Sites and check our Site table is fine.\n",
    "When an entry is null in google spreadsheet, we change it to a NA string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b2966e",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(url + \"sampleTypes/\" + types[\"Site\"] + \"/meta\", headers = headers2)\n",
    "data = r.json()\n",
    "for feat in data.get(\"data\"):\n",
    "    if feat.get(\"sampleDataType\") == \"CHECKBOX\" or feat.get(\"sampleDataType\") == \"COMBO\":\n",
    "        OptionELAB=feat.get(\"optionValues\")\n",
    "        key=feat.get(\"key\")\n",
    "        tableSite.loc[tableSite[key].isnull(),key] = 'NA'\n",
    "        for tabVal in tableSite[key].unique():\n",
    "            if tabVal not in OptionELAB:\n",
    "                print(tabVal + \" not mapped in eLab for \" + key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2be93e",
   "metadata": {},
   "source": [
    "Now, we make the json for each Site and we upload or update in eLab!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98e3915",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###iterate over Sites\n",
    "for index,name in tableSite['Name'].items():     \n",
    "    Data={}\n",
    "    for fea in FeateLabSites.keys():\n",
    "        if FeateLabSites[fea]['ID'] == \"notMeta\":\n",
    "            ###fixed value (from dico)\n",
    "            if SiteDict[fea].startswith(\"fixed\"):\n",
    "                    element=SiteDict[fea].split(\"_\")[1]\n",
    "            elif SiteDict[fea]==\"None\":\n",
    "                    element=\"Nothing entered\"\n",
    "            else:\n",
    "                element=tableSite[fea][index]\n",
    "            Data[fea]=element\n",
    "    ###case of updating\n",
    "    if name in registered['Site'].keys():\n",
    "        #print(name + \" updating\")\n",
    "        patch=True\n",
    "        id=registered['Site'][name]     \n",
    "\n",
    "        Data[\"Note\"]=\"Updated from API\"\n",
    "        DR=requests.patch(url + \"samples/\"+id, headers = headers2,data = Data)\n",
    "    else:\n",
    "        ###case of uploading\n",
    "        #print(name + \" uploading\")\n",
    "        patch=False\n",
    "        Data[\"Note\"]=\"Uploaded from API\"\n",
    "        Data[\"sampleTypeID\"]=types[\"Site\"]\n",
    "        Data[\"Name\"]=name\n",
    "        DR=requests.post(url + \"samples/\", headers = headers2,data = Data)             \n",
    "    ####check the Data loading was correct\n",
    "    if DR.status_code not in [200,204]:\n",
    "        print(\"error for \" + name)\n",
    "        print(DR.status_code)\n",
    "        print(DR.raise_for_status())\n",
    "    ###actualize the registered[\"Site\"] list (checking we did not duplicated anything here)\n",
    "    r=requests.get(url + \"samples/forNames?names=\"+name.replace(\" \",\"%20\"), headers = headers2)\n",
    "    data=r.json()\n",
    "    \n",
    "\n",
    "    sam=data.get(\"data\")\n",
    "    if len(sam)!=1:\n",
    "        print(\"different Site entries (\" + str(len(sam)) + \") for name \"+name)\n",
    "        break\n",
    "    else:\n",
    "        sam=sam[0]\n",
    "        id=str(sam.get(\"sampleID\"))\n",
    "        #print(\"Data OK for \"+ name + \" (\" + id + \")\")\n",
    "        registered[\"Site\"][name]=id\n",
    "\n",
    "    print(\"data already loaded\")\n",
    "    print(data)\n",
    "    ###patch the metaData\n",
    "    ###get loaded values\n",
    "    if patch:\n",
    "        #print(\"patching meta so need to heck if differences\")\n",
    "        MDR=requests.get(url + \"samples/\"+id+\"/meta\", headers = headers2)\n",
    "        if MDR.status_code!=200:\n",
    "            print(\"error querrying meta for \" + name)\n",
    "            break\n",
    "        data=MDR.json().get(\"data\")\n",
    "        metaLoaded={}\n",
    "        for i in data:\n",
    "            metaLoaded[i[\"key\"]]=str(i[\"value\"])\n",
    "    print(\"metadata already loaded\")\n",
    "    print(metaLoaded)\n",
    "    for fea in FeateLabSites.keys():\n",
    "        needToPatch=False\n",
    "        ###get new element to be loaded\n",
    "        if FeateLabSites[fea]['ID'] != \"notMeta\" and FeateLabSites[fea]['TYPE'] != \"FILE\":\n",
    "            ###fixed value (from dico)\n",
    "            if SiteDict[fea].startswith(\"fixed\"):\n",
    "                element=SiteDict[fea].split(\"_\")[1]\n",
    "            elif SiteDict[fea]==\"None\":\n",
    "                element=\"Nothing entered\"\n",
    "            else:\n",
    "                element=tableSite[fea][index]\n",
    "            \n",
    "            ###check if this is a new entry or not\n",
    "            if patch:\n",
    "                ###check if new element is similar to what already loaded\n",
    "                if metaLoaded[fea] != str(element):\n",
    "                    print(\"difference for \" + name + \"(feature: \" + fea + \") \" + format(element) + \" vs loaded : \" + format(metaLoaded[fea]))\n",
    "                    prompt=\"?\"\n",
    "                    #prompt=\"y\"\n",
    "                    while prompt not in [\"y\",\"n\"]:\n",
    "                        prompt = input(\"replace y/n??\")\n",
    "                    if prompt == \"y\":\n",
    "                        needToPatch=True\n",
    "            else:\n",
    "                needToPatch=True\n",
    "\n",
    "            ###if difference ==> we load\n",
    "            if needToPatch:\n",
    "                MetaData={\"key\": fea,\n",
    "                          \"sampleTypeMetaID\": int(FeateLabSites[fea]['ID']),\n",
    "                          \"value\": element,\n",
    "                          \"sampleDataType\": FeateLabSites[fea]['TYPE']}\n",
    "                print(MetaData)\n",
    "                MDR=requests.put(url + \"samples/\"+id+\"/meta\", headers = headers2,data = MetaData)\n",
    "                ####check the MetaData loading was correct\n",
    "                if MDR.status_code not in [200,204]:\n",
    "                    print(\"error for \" + name + \" for feature \" + fea)\n",
    "                    print(MDR.status_code)\n",
    "                    print(MDR.raise_for_status())\n",
    "                    break\n",
    "    #print(\"metadata OK for \"+ name + \" (\" + id + \")\")\n",
    "    \n",
    "    Quant={}\n",
    "    for fea in ['Amount','Unit']:\n",
    "        if SiteDict[fea].startswith(\"fixed\"):\n",
    "            element=SiteDict[fea].split(\"_\")[1]\n",
    "        elif SiteDict[fea]==\"None\":\n",
    "            element=\"Nothing entered\"\n",
    "        else:\n",
    "            element=tableSite[fea][index]\n",
    "        Quant[fea]=element\n",
    "    Quant[\"displayUnit\"]=Quant[\"Unit\"].capitalize()\n",
    "    Quant[\"fullAmount\"]=Quant[\"Amount\"]\n",
    "    QR=requests.put(url + \"samples/\" + id + \"/quantity\", headers = headers2, data = Quant)\n",
    "    if QR.status_code not in [200,204]:\n",
    "        print(\"error for \" + name + \" for quantity\")\n",
    "        print(QR.status_code)\n",
    "        print(QR.raise_for_status())\n",
    "    #else:\n",
    "        #print(\"quantity OK for \"+ name + \" (\" + id + \")\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc4374b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BadRequest(myReq,code=200):\n",
    "    return(myReq.status_code !=code)\n",
    "\n",
    "\n",
    "id=registered[\"Individual\"][\"AR0001\"]\n",
    "getReq=requests.get(url + \"samples/\"+id, headers = headers2)\n",
    "if BadRequest(getReq,200):\n",
    "        print(\"error\")\n",
    "        print(getReq.status_code)\n",
    "        print(getReq.raise_for_status())\n",
    "\n",
    "\n",
    "print(getReq.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fc43f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Data={'description': getReq.json()[\"description\"]+\"\\n TEST HOHEHEINBON\"}\n",
    "patchReq=requests.patch(url + \"samples/\"+id, headers = headers2,data=Data)\n",
    "if BadRequest(patchReq,204):\n",
    "        print(\"error\")\n",
    "        print(patchReq.status_code)\n",
    "        print(patchReq.raise_for_status())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3496c7d",
   "metadata": {},
   "source": [
    "#### Prepare json for uploading and updating Individuals\n",
    "Get features for Individual "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9a6c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(url + \"sampleTypes/\" + types[\"Individual\"] + \"/meta\", headers = headers2)\n",
    "data = r.json()\n",
    "FeateLabInds = {}\n",
    "for feat in ['Name','Description','Note','Amount','Unit',\"parentSampleID\"]:\n",
    "    FeateLabInds[feat] = {\"ID\": \"notMeta\"}\n",
    "for feat in data.get(\"data\"):\n",
    "    FeateLabInds[format(feat.get(\"key\"))] = { \"ID\":format(feat.get(\"sampleTypeMetaID\")),\n",
    "                                              \"TYPE\":format(feat.get(\"sampleDataType\"))}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38eb545",
   "metadata": {},
   "source": [
    "And check that they have been declared IndDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085f4f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in FeateLabInds.keys():\n",
    "    if feat not in IndDict.keys():\n",
    "        print(feat + \"--> NOT IN DICTIONARY\")\n",
    "        \n",
    "for feat in IndDict.keys():\n",
    "    if feat not in FeateLabInds.keys():\n",
    "        print(feat + \"--> NOT IN eLAB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4457df1",
   "metadata": {},
   "source": [
    "Now we make a table of unique entries for relevant columns for individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2366630",
   "metadata": {},
   "outputs": [],
   "source": [
    "tableInd=pandas.DataFrame()\n",
    "for col in list(IndDict.keys()):\n",
    "#        if SiteDict[col] == \"None\":\n",
    "        if IndDict[col] == \"None\" or IndDict[col].startswith(\"fixed\"):\n",
    "            continue\n",
    "        else:\n",
    "            tableInd[col]=table[ IndDict[col]]\n",
    "#print(tableInd)\n",
    "duplicatedInd=tableInd[tableInd['Name'].duplicated(keep=False)]\n",
    "if len(duplicatedInd.index) > 0 :\n",
    "    print(\"DUPLICATED Inds... GO BACK TO THE TABLE AND FIX THOSE\")\n",
    "    print(duplicatedInd.sort_values('Name'))\n",
    "    \n",
    "tableInd['Name']=tableInd['Name'].str.split(\".\",expand=True)[0]\n",
    "tableInd=tableInd.drop_duplicates()\n",
    "\n",
    "print(tableInd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8688558d",
   "metadata": {},
   "source": [
    "Change gender To Male / Female / NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8b6ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Male={\"M\",\n",
    "     \"male\",\n",
    "     \"Male\",\n",
    "     \"Male (Det.)\",\n",
    "     \"Masculino\",\n",
    "     \"masculino\",\n",
    "     \"Male (Estimated)\",\n",
    "     \"Male (Est.)\"}\n",
    "Female={\"F\",\n",
    "        \"female\",\n",
    "        \"Female\",\n",
    "        \"Female (Det.)\",\n",
    "        \"femenino\",\n",
    "        \"Femenino\",\n",
    "        \"Female (Estimated)\",\n",
    "        \"Female (Est.)\"}\n",
    "NA={\"I\",\"F?\",\"M?\",\"Unknown\",\"ND\",\"IN\",\"-\",\"Female?\",\"NA\",\"Undefined\",\"indet\",\"Indeterminado\",\"?\",\"No determinado\"}\n",
    "\n",
    "tableInd.loc[tableInd[\"Gender\"].isnull(),\"Gender\"]='NA'\n",
    "for index, ele in tableInd[\"Gender\"].items():\n",
    "    if ele in Male:\n",
    "        tableInd.at[index,\"Gender\"]=\"Male\"\n",
    "    elif ele in Female:\n",
    "        tableInd.at[index,\"Gender\"]=\"Female\"\n",
    "    elif ele in NA:\n",
    "        tableInd.at[index,\"Gender\"]=\"NA\"\n",
    "    else:\n",
    "        print(ele + \" not defined\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249cef70",
   "metadata": {},
   "source": [
    "We get all the possible values for checkboxes and dropdown features of Individuals and check our Individual table is fine. When an entry is null in google spreadsheet, we change it to a NA string.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a81bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(url + \"sampleTypes/\" + types[\"Individual\"] + \"/meta\", headers = headers2)\n",
    "data = r.json()\n",
    "for feat in data.get(\"data\"):\n",
    "    if feat.get(\"sampleDataType\") == \"CHECKBOX\" or feat.get(\"sampleDataType\") == \"COMBO\":\n",
    "        OptionELAB=feat.get(\"optionValues\")\n",
    "        key=feat.get(\"key\")\n",
    "        tableInd.loc[tableInd[key].isnull(),key]='NA'\n",
    "        for tabVal in tableInd[key].unique():\n",
    "            if tabVal not in OptionELAB:\n",
    "                print(\"--\" + tabVal + \"-- not mapped in eLab for \" + key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4263eb3f",
   "metadata": {},
   "source": [
    "Check if duplicated entries (meaning that some fields are inconsistent across different lines for same individual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0792dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicatedInd=tableInd.drop_duplicates()\n",
    "duplicatedInd=duplicatedInd[duplicatedInd['Name'].duplicated(keep=False)]\n",
    "if len(duplicatedInd.index) > 0 :\n",
    "    print(\"DUPLICATED Individuals... GO BACK TO THE TABLE AND FIX THOSE\")\n",
    "    print(duplicatedInd.sort_values('Name'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9203a95",
   "metadata": {},
   "source": [
    "Now, we make the json for each Individual and we upload or update in eLab!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1507086",
   "metadata": {},
   "outputs": [],
   "source": [
    "###iterate over Individuals\n",
    "for index,name in tableInd['Name'].items():\n",
    "    ####load the Data!\n",
    "    Data={}\n",
    "    for fea in FeateLabInds.keys():\n",
    "        if FeateLabInds[fea]['ID'] == \"notMeta\":\n",
    "            ###fixed value (from dico)\n",
    "            if IndDict[fea].startswith(\"fixed\"):\n",
    "                element=IndDict[fea].split(\"_\")[1]\n",
    "            elif IndDict[fea]==\"None\":\n",
    "                element=\"Nothing entered\"\n",
    "            elif fea == \"parentSampleID\":\n",
    "                #element=tableInd[fea][index]+\"|\"+registered[IndDict[fea]][tableInd[fea][index]]\n",
    "                if format(tableInd[fea][index])==\"nan\":\n",
    "                    element=0\n",
    "                else:\n",
    "                    element=registered[IndDict[fea]][tableInd[fea][index]]\n",
    "            else:\n",
    "                element=tableInd[fea][index]\n",
    "            Data[fea]=element\n",
    "    ###case of updating\n",
    "    if name in registered['Individual'].keys():\n",
    "        #print(name + \"updating\")\n",
    "        patch=True\n",
    "        id=registered['Individual'][name]\n",
    "        Data[\"Note\"]=\"Updated from API\"\n",
    "        ###QUERY CAMPO\n",
    "        ##SI CAMPO ELAB <> CAMPO TABLA:\n",
    "        ##        proimpt: update???\n",
    "            \n",
    "        DR=requests.patch(url + \"samples/\"+id, headers = headers2,data = Data)\n",
    "    else:\n",
    "        ###case of uploading\n",
    "        #print(name + \"uploading\")\n",
    "        patch=False\n",
    "        Data[\"Note\"]=\"Uploaded from API\"\n",
    "        Data[\"sampleTypeID\"]=types[\"Individual\"]\n",
    "        Data[\"Name\"]=name\n",
    "        DR=requests.post(url + \"samples/\", headers = headers2,data = Data)             \n",
    "    ####check the Data loading was correct\n",
    "    if DR.status_code not in [200,204]:\n",
    "        print(\"error for \" + name)\n",
    "        print(DR.status_code)\n",
    "        print(DR.raise_for_status())\n",
    "    ###actualize the registered[\"Site\"] list (checking we did not duplicated anything here)\n",
    "    r=requests.get(url + \"samples/forNames?names=\"+name, headers = headers2)\n",
    "    data=r.json()\n",
    "    sam=data.get(\"data\")\n",
    "    if len(sam)!=1:\n",
    "        print(\"different Individual entries (\" + str(len(sam)) + \") for name \"+name)\n",
    "        break\n",
    "    else:\n",
    "        sam=sam[0]\n",
    "        id=str(sam.get(\"sampleID\"))\n",
    "        #print(\"Data OK for \"+ name + \" (\" + id + \")\")\n",
    "        registered[\"Individual\"][name]=id\n",
    "\n",
    "    ###patch the metaData\n",
    "    if patch:\n",
    "        #print(\"patching meta so need to heck if differences for \"+name)\n",
    "        MDR=requests.get(url + \"samples/\"+id+\"/meta\", headers = headers2)\n",
    "        if MDR.status_code!=200:\n",
    "            print(\"error querrying meta for \" + name)\n",
    "            break\n",
    "        data=MDR.json().get(\"data\")\n",
    "        metaLoaded={}\n",
    "        for i in data:\n",
    "            metaLoaded[i[\"key\"]]=str(i[\"value\"])\n",
    "\n",
    "    for fea in FeateLabInds.keys():\n",
    "        needToPatch=False\n",
    "        ###get new element to be loaded\n",
    "        if FeateLabInds[fea]['ID'] != \"notMeta\" and FeateLabInds[fea]['TYPE'] != \"FILE\":\n",
    "            ###fixed value (from dico)\n",
    "            if IndDict[fea].startswith(\"fixed\"):\n",
    "                element=IndDict[fea].split(\"_\")[1]\n",
    "                MetaData={\"key\": fea,\n",
    "                          \"sampleTypeMetaID\": int(FeateLabInds[fea]['ID']),\n",
    "                          \"value\": element,\n",
    "                          \"sampleDataType\": FeateLabInds[fea]['TYPE']}\n",
    "            elif IndDict[fea]==\"None\":\n",
    "                element=\"Nothing entered\"\n",
    "                MetaData={\"key\": fea,\n",
    "                          \"sampleTypeMetaID\": int(FeateLabInds[fea]['ID']),\n",
    "                          \"value\": element,\n",
    "                          \"sampleDataType\": FeateLabInds[fea]['TYPE']}\n",
    "            elif FeateLabInds[fea]['TYPE'] == \"SAMPLELINK\" and format(tableInd[fea][index])!=\"nan\":\n",
    "                samples=[]\n",
    "                splitted=tableInd[fea][index].split(\",\")\n",
    "                splitted=list(dict.fromkeys(splitted))\n",
    "                for sisi in splitted:\n",
    "                    IDsisi=registered[IndDict[fea]][sisi]\n",
    "                    samples.append({\"sampleID\": IDsisi,\"name\": sisi})\n",
    "                    if sisi != splitted[0]:\n",
    "                        element=element+\",\"+sisi+\"|\"+IDsisi\n",
    "                    else:\n",
    "                        element=sisi+\"|\"+IDsisi\n",
    "                MetaData={\n",
    "                    \"sampleTypeMetaID\": int(FeateLabInds[fea]['ID']),\n",
    "                    \"sampleDataType\": FeateLabInds[fea]['TYPE'],\n",
    "                    \"samples\": samples,\n",
    "                    \"key\": fea,\n",
    "                    \"value\": element\n",
    "                }\n",
    "            else:\n",
    "                element=tableInd[fea][index]\n",
    "                if format(element)==\"nan\" :\n",
    "                    element=\"NA\"\n",
    "                MetaData={\"key\": fea,\n",
    "                          \"sampleTypeMetaID\": int(FeateLabInds[fea]['ID']),\n",
    "                          \"value\": element,\n",
    "                          \"sampleDataType\": FeateLabInds[fea]['TYPE']}\n",
    "            \n",
    "            ###check if this is a new entry or not\n",
    "            if patch:\n",
    "                ###check if new element is similar to what already loaded\n",
    "                if metaLoaded[fea] != str(element):\n",
    "                    print(\"difference for \" + name + \"(feature: \" + fea + \") \" + element + \" vs loaded : \" + metaLoaded[fea])\n",
    "                    #prompt=\"y\"\n",
    "                    prompt=\"?\"\n",
    "                    while prompt not in [\"y\",\"n\"]:\n",
    "                        prompt = input(\"replace y/n??\")\n",
    "                    if prompt == \"y\":\n",
    "                        needToPatch=True\n",
    "            else:\n",
    "                needToPatch=True\n",
    "    \n",
    "            if needToPatch:\n",
    "                #print(MetaData)      \n",
    "                MDR=requests.put(url + \"samples/\"+id+\"/meta\", headers = headers2,data = MetaData)\n",
    "                ####check the MetaData loading was correct\n",
    "                if MDR.status_code not in [200,204]:\n",
    "                    print(\"error for \" + name + \" for feature \" + fea)\n",
    "                    print(MDR.status_code)\n",
    "                    print(MDR.raise_for_status())\n",
    "                    break\n",
    "    #print(\"metadata OK for \"+ name + \" (\" + id + \")\")\n",
    "    ###patch the quantity\n",
    "    Quant={}\n",
    "    for fea in ['Amount','Unit']:\n",
    "        if IndDict[fea].startswith(\"fixed\"):\n",
    "            element=IndDict[fea].split(\"_\")[1]\n",
    "        elif IndDict[fea]==\"None\":\n",
    "            element=\"Nothing entered\"\n",
    "        else:\n",
    "            element=tableInd[fea][index]\n",
    "        Quant[fea]=element\n",
    "    Quant[\"displayUnit\"]=Quant[\"Unit\"].capitalize()\n",
    "    Quant[\"fullAmount\"]=Quant[\"Amount\"]\n",
    "    QR=requests.put(url + \"samples/\" + id + \"/quantity\", headers = headers2, data = Quant)\n",
    "    if QR.status_code not in [200,204]:\n",
    "        print(\"error for \" + name + \" for quantity\")\n",
    "        print(QR.status_code)\n",
    "        print(QR.raise_for_status())\n",
    "    #else:\n",
    "    #    print(\"quantity OK for \"+ name + \" (\" + id + \")\")\n",
    "\n",
    "print(\"finished\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56913a76",
   "metadata": {},
   "source": [
    "#### Prepare json for uploading and updating Skeleton elements\n",
    "Get features for Skeleton elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8589b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(url + \"sampleTypes/\" + types[\"Skeleton Element\"] + \"/meta\", headers = headers2)\n",
    "data = r.json()\n",
    "FeateLabSkel = {}\n",
    "for feat in ['Name','Description','Note','Amount','Unit',\"parentSampleID\"]:\n",
    "    FeateLabSkel[feat] = {\"ID\": \"notMeta\"}\n",
    "for feat in data.get(\"data\"):\n",
    "    FeateLabSkel[format(feat.get(\"key\"))] = { \"ID\":format(feat.get(\"sampleTypeMetaID\")),\n",
    "                                              \"TYPE\":format(feat.get(\"sampleDataType\"))}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2af2be2",
   "metadata": {},
   "source": [
    "And check that they have been declared SkeDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e315f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in FeateLabSkel.keys():\n",
    "    if feat not in SkeDict.keys():\n",
    "        print(feat + \"--> NOT IN DICTIONARY\")\n",
    "        \n",
    "for feat in SkeDict.keys():\n",
    "    if feat not in FeateLabSkel.keys():\n",
    "        print(feat + \"--> NOT IN eLAB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b2f99c",
   "metadata": {},
   "source": [
    "We get all the possible values for checkboxes and dropdown features of Skeleton Elements and check our Skeleton Elements table is fine. When an entry is null in google spreadsheet, we change it to a NA string.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e309e8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(url + \"sampleTypes/\" + types[\"Skeleton Element\"] + \"/meta\", headers = headers2)\n",
    "data = r.json()\n",
    "for feat in data.get(\"data\"):\n",
    "    if feat.get(\"sampleDataType\") == \"CHECKBOX\" or feat.get(\"sampleDataType\") == \"COMBO\":\n",
    "        OptionELAB=feat.get(\"optionValues\")\n",
    "        key=feat.get(\"key\")\n",
    "        #table.loc[tableInd[key].isnull(),key]='NA'\n",
    "        for tabVal in table[SkeDict[key]].unique():\n",
    "            if tabVal not in OptionELAB:\n",
    "                print(\"--\" + tabVal + \"-- not mapped in eLab for \" + key)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d302d951",
   "metadata": {},
   "source": [
    "Download extract file from metapaleo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41449548",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import paramiko \n",
    "\n",
    "user = open(\"credentials/sftpUser\",\"r\").readline().strip().split(\"\\t\")\n",
    "psw=user[1]\n",
    "user=user[0]\n",
    "\n",
    "ssh = paramiko.SSHClient()\n",
    "ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "\n",
    "ssh.connect('sftpcampus.pasteur.fr', username=user, password=psw)\n",
    "sftp = ssh.open_sftp()\n",
    "localpath = './DDBB_extracts.csv'\n",
    "remotepath = '/pasteur/entites/metapaleo/Research/ERC-project/Samples/LabellingExtracts/DDBB_extracts.csv'\n",
    "sftp.get(remotepath,localpath)\n",
    "sftp.close()\n",
    "ssh.close()\n",
    "\n",
    "extractTable=pandas.read_csv(\"DDBB_extracts.csv\",delimiter=\";\")\n",
    "extractTable[\"RascovanLabID\"]=None\n",
    "for index,name in extractTable[\"ExtractID\"].items():\n",
    "    extractTable.loc[index,\"RascovanLabID\"]=\".\".join(name.split(\".\")[0:2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd9ef17",
   "metadata": {},
   "source": [
    "and compile it to the table for \"Pictures\" and \"General Sample Comment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bfc328",
   "metadata": {},
   "outputs": [],
   "source": [
    "skelTablefromEx=pandas.DataFrame()\n",
    "for key in [\"RascovanLabID\",\"Pictures\",\"GeneralSampleComment\"]:\n",
    "    skelTablefromEx[key]=extractTable[key]\n",
    "\n",
    "    \n",
    "skelTablefromEx=skelTablefromEx.drop_duplicates()\n",
    "###duplicated (UNEXPECTED!)\n",
    "dupSkefromEx=skelTablefromEx.loc[skelTablefromEx[\"RascovanLabID\"].duplicated(keep=False)]\n",
    "if len(dupSkefromEx):\n",
    "    print(\"DUPLICATED rascoIDs in extract file\")\n",
    "    print(dupSkefromEx)\n",
    "\n",
    "    \n",
    "table[\"DrillingPictures\"]=None\n",
    "table[\"GeneralSampleComment\"]=None\n",
    "\n",
    "for index,rascoID in table[\"RascovanLabID\"].items():\n",
    "    #print(str(index)+\" \"+rascoID)\n",
    "    pic=\"NA\"\n",
    "    com=\"NA\"\n",
    "    if rascoID in list(skelTablefromEx[\"RascovanLabID\"]):\n",
    "        if list(skelTablefromEx.loc[skelTablefromEx[\"RascovanLabID\"]==rascoID,\"Pictures\"])[0] == \"T\":\n",
    "            pic=\"/pasteur/entites/metapaleo/Research/ERC-project/Samples/pictures/Drilling/\"+rascoID\n",
    "        com=list(skelTablefromEx.loc[skelTablefromEx[\"RascovanLabID\"]==rascoID,\"GeneralSampleComment\"])[0]\n",
    "    #print(rascoID+\" \"+com+\" \"+pic)\n",
    "    table.loc[index,\"DrillingPictures\"]=pic\n",
    "    table.loc[index,\"GeneralSampleComment\"]=com\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8c0fab",
   "metadata": {},
   "source": [
    "Check if duplicated entries (meaning that some fields are inconsistent across different lines for same skeleton element)\n",
    "Check if no duplicated skeleton element nor archaeologist ID for skel element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74436081",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicatedAR=table[table[SkeDict['Name']].duplicated(keep=False)]\n",
    "if len(duplicatedAR.index):\n",
    "    print(\"DUPLICATED rascoIDs\")\n",
    "    print(duplicatedAR)\n",
    "\n",
    "duplicatedSam=table.loc[table[SkeDict['Archaeologist sample ID']].duplicated(keep=False)]\n",
    "if len(duplicatedSam.index):\n",
    "    print(\"DUPLICATED archeologist ID\")\n",
    "    print(duplicatedSam[[SkeDict[x] for x in [\"Name\",\"Archaeologist sample ID\"]]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f81584",
   "metadata": {},
   "source": [
    "Now, we make the json for each Skeleton element and we upload or update in eLab!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b077b5a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "table.loc[table[SkeDict['Name']]==\"AR0036.1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2484732",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###iterate over Skeleton Elements\n",
    "for index,name in table[SkeDict['Name']].items():\n",
    "    ####load the Data!\n",
    "    Data={}\n",
    "    for fea in FeateLabSkel.keys():\n",
    "        if FeateLabSkel[fea]['ID'] == \"notMeta\":\n",
    "            ###fixed value (from dico)\n",
    "            if SkeDict[fea].startswith(\"fixed\"):\n",
    "                element=SkeDict[fea].split(\"_\")[1]\n",
    "            elif SkeDict[fea]==\"None\":\n",
    "                element=\"Nothing entered\"\n",
    "            elif fea == \"parentSampleID\":\n",
    "                element=name.split(\".\")[0]\n",
    "                if element not in registered[\"Individual\"]:\n",
    "                    print(\"can't not set \"+element+\" as parent sample\")\n",
    "                    break\n",
    "                element=registered[\"Individual\"][element]\n",
    "            else:\n",
    "                element=table[SkeDict[fea]][index]\n",
    "            Data[fea]=element\n",
    "    ###case of updating\n",
    "    if name in registered['Skeleton Element'].keys():\n",
    "        #print(name + \"updating\")\n",
    "        patch=True\n",
    "        id=registered['Skeleton Element'][name]\n",
    "        Data[\"Note\"]=\"Updated from API\"\n",
    "        ###QUERY CAMPO\n",
    "        ##SI CAMPO ELAB <> CAMPO TABLA:\n",
    "        ##        proimpt: update???\n",
    "            \n",
    "        DR=requests.patch(url + \"samples/\"+id, headers = headers2,data = Data)\n",
    "    else:\n",
    "        ###case of uploading\n",
    "        #print(name + \"uploading\")\n",
    "        patch=False\n",
    "        Data[\"Note\"]=\"Uploaded from API\"\n",
    "        Data[\"sampleTypeID\"]=types[\"Skeleton Element\"]\n",
    "        Data[\"Name\"]=name\n",
    "        DR=requests.post(url + \"samples/\", headers = headers2,data = Data)             \n",
    "    ####check the Data loading was correct\n",
    "    if DR.status_code not in [200,204]:\n",
    "        print(\"error for \" + name)\n",
    "        print(DR.status_code)\n",
    "        print(DR.raise_for_status())\n",
    "    ###actualize the registered[\"Site\"] list (checking we did not duplicated anything here)\n",
    "    r=requests.get(url + \"samples/forNames?names=\"+name, headers = headers2)\n",
    "    data=r.json()\n",
    "    sam=data.get(\"data\")\n",
    "    if len(sam)!=1:\n",
    "        print(\"different Skeleton Element entries (\" + str(len(sam)) + \") for name \"+name)\n",
    "        break\n",
    "    else:\n",
    "        sam=sam[0]\n",
    "        id=str(sam.get(\"sampleID\"))\n",
    "        #print(\"Data OK for \"+ name + \" (\" + id + \")\")\n",
    "        registered[\"Skeleton Element\"][name]=id\n",
    "\n",
    "    ###patch the metaData\n",
    "    if patch:\n",
    "        #print(\"patching meta so need to heck if differences for \"+name)\n",
    "        MDR=requests.get(url + \"samples/\"+id+\"/meta\", headers = headers2)\n",
    "        if MDR.status_code!=200:\n",
    "            print(\"error querrying meta for \" + name)\n",
    "            break\n",
    "        data=MDR.json().get(\"data\")\n",
    "        metaLoaded={}\n",
    "        for i in data:\n",
    "            metaLoaded[i[\"key\"]]=str(i[\"value\"])\n",
    "\n",
    "    for fea in FeateLabSkel.keys():\n",
    "        needToPatch=False\n",
    "        ###get new element to be loaded\n",
    "        if FeateLabSkel[fea]['ID'] != \"notMeta\" and FeateLabSkel[fea]['TYPE'] != \"FILE\":\n",
    "            ###fixed value (from dico)\n",
    "            if SkeDict[fea].startswith(\"fixed\"):\n",
    "                element=SkeDict[fea].split(\"_\")[1]\n",
    "                MetaData={\"key\": fea,\n",
    "                          \"sampleTypeMetaID\": int(FeateLabSkel[fea]['ID']),\n",
    "                          \"value\": element,\n",
    "                          \"sampleDataType\": FeateLabSkel[fea]['TYPE']}\n",
    "            elif SkeDict[fea]==\"None\":\n",
    "                element=\"Nothing entered\"\n",
    "                MetaData={\"key\": fea,\n",
    "                          \"sampleTypeMetaID\": int(FeateLabSkel[fea]['ID']),\n",
    "                          \"value\": element,\n",
    "                          \"sampleDataType\": FeateLabSkel[fea]['TYPE']}\n",
    "            elif fea == \"From Individual\":\n",
    "                sisi=name.split(\".\")[0]\n",
    "                IDsisi=registered[\"Individual\"][sisi]\n",
    "                element=sisi+\"|\"+IDsisi\n",
    "                MetaData={\n",
    "                   \"sampleTypeMetaID\": int(FeateLabSkel[fea]['ID']),\n",
    "                   \"sampleDataType\": FeateLabSkel[fea]['TYPE'],\n",
    "                   \"samples\": sisi,\n",
    "                    \"key\": fea,\n",
    "                    \"value\": element\n",
    "                }\n",
    "            else:\n",
    "                element=table[SkeDict[fea]][index]\n",
    "                if format(element)==\"nan\" :\n",
    "                    element=\"NA\"\n",
    "                MetaData={\"key\": fea,\n",
    "                          \"sampleTypeMetaID\": int(FeateLabSkel[fea]['ID']),\n",
    "                          \"value\": element,\n",
    "                          \"sampleDataType\": FeateLabSkel[fea]['TYPE']}\n",
    "            \n",
    "            ###check if this is a new entry or not\n",
    "            if patch:\n",
    "                ###check if new element is similar to what already loaded\n",
    "                if fea not in metaLoaded.keys(): \n",
    "                    needToPatch=True\n",
    "                elif metaLoaded[fea] != str(element):\n",
    "                    print(\"difference for \" + name + \"(feature: \" + fea + \") \" + element + \" vs loaded : \" + metaLoaded[fea])\n",
    "                    #prompt=\"y\"\n",
    "                    if fea == \"Pictures Labelling\" or fea == \"Exportation Permit Number\":\n",
    "                        prompt=\"y\"\n",
    "                    else:\n",
    "                        prompt=\"?\"\n",
    "                    while prompt not in [\"y\",\"n\"]:\n",
    "                        prompt = input(\"replace y/n??\")\n",
    "                    if prompt == \"y\":\n",
    "                        needToPatch=True\n",
    "            else:\n",
    "                needToPatch=True\n",
    "    \n",
    "            if needToPatch:\n",
    "                #print(MetaData)      \n",
    "                MDR=requests.put(url + \"samples/\"+id+\"/meta\", headers = headers2,data = MetaData)\n",
    "                ####check the MetaData loading was correct\n",
    "                if MDR.status_code not in [200,204]:\n",
    "                    print(\"error for \" + name + \" for feature \" + fea)\n",
    "                    print(MDR.status_code)\n",
    "                    print(MDR.raise_for_status())\n",
    "                    break\n",
    "    #print(\"metadata OK for \"+ name + \" (\" + id + \")\")\n",
    "    ###patch the quantity\n",
    "    Quant={}\n",
    "    for fea in ['Amount','Unit']:\n",
    "        if SkeDict[fea].startswith(\"fixed\"):\n",
    "            element=SkeDict[fea].split(\"_\")[1]\n",
    "        elif SkeDict[fea]==\"None\":\n",
    "            element=\"Nothing entered\"\n",
    "        else:\n",
    "            element=table[SkeDict[fea]][index]\n",
    "        Quant[fea]=element\n",
    "    Quant[\"displayUnit\"]=Quant[\"Unit\"].capitalize()\n",
    "    Quant[\"fullAmount\"]=Quant[\"Amount\"]\n",
    "    QR=requests.put(url + \"samples/\" + id + \"/quantity\", headers = headers2, data = Quant)\n",
    "    if QR.status_code not in [200,204]:\n",
    "        print(\"error for \" + name + \" for quantity\")\n",
    "        print(QR.status_code)\n",
    "        print(QR.raise_for_status())\n",
    "    #else:\n",
    "    #    print(\"quantity OK for \"+ name + \" (\" + id + \")\")\n",
    "    \n",
    "    #if index > 9:\n",
    "    #    print(\"break after 10\")\n",
    "    #    break \n",
    "print(\"finished\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71775041",
   "metadata": {},
   "source": [
    "### For Extracts\n",
    "We start from DDBB_extracts.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6635e78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(url + \"sampleTypes/\" + types[\"Extract\"] + \"/meta\", headers = headers2)\n",
    "data = r.json()\n",
    "FeateLabExe = {}\n",
    "for feat in ['Name','Description','Note','Amount','Unit',\"parentSampleID\"]:\n",
    "    FeateLabExe[feat] = {\"ID\": \"notMeta\"}\n",
    "for feat in data.get(\"data\"):\n",
    "    FeateLabExe[format(feat.get(\"key\"))] = { \"ID\":format(feat.get(\"sampleTypeMetaID\")),\n",
    "                                              \"TYPE\":format(feat.get(\"sampleDataType\"))}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60c36bf",
   "metadata": {},
   "source": [
    "And check that they have been declared ExeDict.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18ccfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in FeateLabExe.keys():\n",
    "    if feat not in ExeDict.keys():\n",
    "        print(feat + \"--> NOT IN DICTIONARY\")\n",
    "        \n",
    "for feat in ExeDict.keys():\n",
    "    if feat not in FeateLabExe.keys():\n",
    "        print(feat + \"--> NOT IN eLAB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fa9dd4",
   "metadata": {},
   "source": [
    "We get all the possible values for checkboxes and dropdown features of Extracts and check our extractTable table is fine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57b721c",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(url + \"sampleTypes/\" + types[\"Extract\"] + \"/meta\", headers = headers2)\n",
    "data = r.json()\n",
    "for feat in data.get(\"data\"):\n",
    "    if feat.get(\"sampleDataType\") == \"CHECKBOX\" or feat.get(\"sampleDataType\") == \"COMBO\":\n",
    "        OptionELAB=feat.get(\"optionValues\")\n",
    "        key=feat.get(\"key\")\n",
    "        if ExeDict[key].startswith(\"fixed\"):\n",
    "            tabVal=ExeDict[key].split(\"_\")[1]\n",
    "            if tabVal not in OptionELAB:\n",
    "                print(\"--\" + tabVal + \"-- not mapped in eLab for \" + key)\n",
    "        else:\n",
    "            extractTable.loc[extractTable[ExeDict[key]].isnull(),ExeDict[key]]=\"NA\"\n",
    "            for tabVal in extractTable[ExeDict[key]].unique():\n",
    "                if tabVal not in OptionELAB:\n",
    "                    print(\"--\" + tabVal + \"-- not mapped in eLab for \" + key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da718606",
   "metadata": {},
   "source": [
    "Now, we make the json for each extract and we upload or update in eLab!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753567b1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###iterate over extracts\n",
    "for index,name in extractTable[ExeDict['Name']].items():\n",
    "    #print(str(index)+\" \"+name)\n",
    "    ####load the Data!\n",
    "    Data={}\n",
    "    for fea in FeateLabExe.keys():\n",
    "        if FeateLabExe[fea]['ID'] == \"notMeta\":\n",
    "            ###fixed value (from dico)\n",
    "            if ExeDict[fea].startswith(\"fixed\"):\n",
    "                element=ExeDict[fea].split(\"_\")[1]\n",
    "            elif ExeDict[fea]==\"None\":\n",
    "                element=\"Nothing entered\"\n",
    "            elif fea == \"parentSampleID\":\n",
    "                if not name.startswith(\"Blank\"):\n",
    "                    element=registered[\"Skeleton Element\"][extractTable[\"RascovanLabID\"][index]]\n",
    "                else:\n",
    "                    element=None\n",
    "            else:\n",
    "                element=extractTable[ExeDict[fea]][index]\n",
    "            Data[fea]=element\n",
    "    ###case of updating\n",
    "    if name in registered['Extract'].keys():\n",
    "        #print(name + \"updating\")\n",
    "        patch=True\n",
    "        id=registered['Extract'][name]\n",
    "        Data[\"Note\"]=\"Updated from API\"\n",
    "        ###QUERY CAMPO\n",
    "        ##SI CAMPO ELAB <> CAMPO TABLA:\n",
    "        ##        proimpt: update???\n",
    "            \n",
    "        DR=requests.patch(url + \"samples/\"+id, headers = headers2,data = Data)\n",
    "    else:\n",
    "        ###case of uploading\n",
    "        #print(name + \"uploading\")\n",
    "        patch=False\n",
    "        Data[\"Note\"]=\"Uploaded from API\"\n",
    "        Data[\"sampleTypeID\"]=types[\"Extract\"]\n",
    "        Data[\"Name\"]=name\n",
    "        DR=requests.post(url + \"samples/\", headers = headers2,data = Data)             \n",
    "    ####check the Data loading was correct\n",
    "    if DR.status_code not in [200,204]:\n",
    "        print(\"error for \" + name)\n",
    "        print(DR.status_code)\n",
    "        print(DR.raise_for_status())\n",
    "    ###actualize the registered[\"Site\"] list (checking we did not duplicated anything here)\n",
    "    r=requests.get(url + \"samples/forNames?names=\"+name, headers = headers2)\n",
    "    data=r.json()\n",
    "    sam=data.get(\"data\")\n",
    "    if len(sam)!=1:\n",
    "        print(\"different Extract entries (\" + str(len(sam)) + \") for name \"+name)\n",
    "        break\n",
    "    else:\n",
    "        sam=sam[0]\n",
    "        id=str(sam.get(\"sampleID\"))\n",
    "        #print(\"Data OK for \"+ name + \" (\" + id + \")\")\n",
    "        registered[\"Extract\"][name]=id\n",
    "\n",
    "    ###patch the metaData\n",
    "    if patch:\n",
    "        #print(\"patching meta so need to heck if differences for \"+name)\n",
    "        MDR=requests.get(url + \"samples/\"+id+\"/meta\", headers = headers2)\n",
    "        if MDR.status_code!=200:\n",
    "            print(\"error querrying meta for \" + name)\n",
    "            break\n",
    "        data=MDR.json().get(\"data\")\n",
    "        metaLoaded={}\n",
    "        for i in data:\n",
    "            metaLoaded[i[\"key\"]]=str(i[\"value\"])\n",
    "\n",
    "    for fea in FeateLabExe.keys():\n",
    "        needToPatch=False\n",
    "        MDR=requests.get(url + \"samples/\"+id+\"/meta\", headers = headers2)\n",
    "        ###get new element to be loaded\n",
    "        if FeateLabExe[fea]['ID'] != \"notMeta\" and FeateLabExe[fea]['TYPE'] != \"FILE\":\n",
    "            ###fixed value (from dico)\n",
    "            if ExeDict[fea].startswith(\"fixed\"):\n",
    "                element=ExeDict[fea].split(\"_\")[1]\n",
    "                MetaData={\"key\": fea,\n",
    "                          \"sampleTypeMetaID\": int(FeateLabExe[fea]['ID']),\n",
    "                          \"value\": element,\n",
    "                          \"sampleDataType\": FeateLabExe[fea]['TYPE']}\n",
    "            elif ExeDict[fea]==\"None\":\n",
    "                element=\"Nothing entered\"\n",
    "                MetaData={\"key\": fea,\n",
    "                          \"sampleTypeMetaID\": int(FeateLabExe[fea]['ID']),\n",
    "                          \"value\": element,\n",
    "                          \"sampleDataType\": FeateLabExe[fea]['TYPE']}\n",
    "            elif fea == \"From Skeleton Element\":\n",
    "                if not name.startswith(\"Blank\"):\n",
    "                    sisi=extractTable[\"RascovanLabID\"][index]\n",
    "                    IDsisi=registered[\"Skeleton Element\"][sisi]\n",
    "                    element=sisi+\"|\"+IDsisi\n",
    "                    samples={\"sampleID\": IDsisi,\"name\": sisi}\n",
    "                else:\n",
    "                    samples=[]\n",
    "                    splitted=extractTable[\"extractionComment\"][index].split(\",\")\n",
    "                    splitted=list(dict.fromkeys(splitted))\n",
    "                    for sisi in splitted:\n",
    "                        IDsisi=registered[\"Extract\"][sisi]\n",
    "                        samples.append({\"sampleID\": IDsisi,\"name\": sisi})\n",
    "                        if sisi != splitted[0]:\n",
    "                            element=element+\"|\"+sisi+\"|\"+IDsisi\n",
    "                        else:\n",
    "                            element=sisi+\"|\"+IDsisi\n",
    "                MetaData={\n",
    "                    \"sampleTypeMetaID\": int(FeateLabExe[fea]['ID']),\n",
    "                    \"sampleDataType\": FeateLabExe[fea]['TYPE'],\n",
    "                    \"samples\": samples,\n",
    "                    \"key\": fea,\n",
    "                    \"value\": element\n",
    "                }\n",
    "            else:\n",
    "                element=extractTable[ExeDict[fea]][index]\n",
    "                if format(element)==\"nan\" or format(element)==\"\" or format(element)==\" \":\n",
    "                    element=\"Nothing entered\"\n",
    "                MetaData={\"key\": fea,\n",
    "                          \"sampleTypeMetaID\": int(FeateLabExe[fea]['ID']),\n",
    "                          \"value\": element,\n",
    "                          \"sampleDataType\": FeateLabExe[fea]['TYPE']}\n",
    "            \n",
    "            ###check if this is a new entry or not\n",
    "            if patch:\n",
    "                ###check if new element is similar to what already loaded\n",
    "                if fea not in metaLoaded.keys(): \n",
    "                    needToPatch=True\n",
    "                elif metaLoaded[fea] != str(element):\n",
    "                    print(\"difference for \" + name + \"(feature: \" + fea + \") \" + element + \" vs loaded : \" + metaLoaded[fea])\n",
    "                    #prompt=\"y\"\n",
    "                    prompt=\"?\"\n",
    "                    while prompt not in [\"y\",\"n\"]:\n",
    "                        prompt = input(\"replace y/n??\")\n",
    "                    if prompt == \"y\":\n",
    "                        needToPatch=True\n",
    "            else:\n",
    "                needToPatch=True\n",
    "    \n",
    "            if needToPatch:\n",
    "                #print(MetaData)      \n",
    "                MDR=requests.put(url + \"samples/\"+id+\"/meta\", headers = headers2,data = MetaData)\n",
    "                ####check the MetaData loading was correct\n",
    "                if MDR.status_code not in [200,204]:\n",
    "                    print(\"error for \" + name + \" for feature \" + fea)\n",
    "                    print(MDR.status_code)\n",
    "                    print(MDR.raise_for_status())\n",
    "                    break\n",
    "    #print(\"metadata OK for \"+ name + \" (\" + id + \")\")\n",
    "    ###patch the quantity\n",
    "    Quant={}\n",
    "    Note=None\n",
    "    for fea in ['Amount','Unit']:\n",
    "        if ExeDict[fea].startswith(\"fixed\"):\n",
    "            element=ExeDict[fea].split(\"_\")[1]\n",
    "        elif ExeDict[fea]==\"None\":\n",
    "            element=\"Nothing entered\"\n",
    "        else:\n",
    "            element=extractTable[ExeDict[fea]][index]\n",
    "            if format(element)==\"nan\":\n",
    "                element=0\n",
    "            elif \"<\" in element:\n",
    "                Note=\"actual weight reported: \"+element\n",
    "                element=0\n",
    "        Quant[fea]=element\n",
    "    Quant[\"displayUnit\"]=Quant[\"Unit\"].capitalize()\n",
    "    Quant[\"fullAmount\"]=Quant[\"Amount\"]\n",
    "    QR=requests.put(url + \"samples/\" + id + \"/quantity\", headers = headers2, data = Quant)\n",
    "    if QR.status_code not in [200,204]:\n",
    "        print(\"error for \" + name + \" for quantity\")\n",
    "        print(QR.status_code)\n",
    "        print(QR.raise_for_status())\n",
    "    ###put actual weight in note when there is a \"<\"\n",
    "    if Note is not None:\n",
    "            r=requests.get(url + \"samples/\"+id, headers = headers2)\n",
    "            if r.status_code not in [200,204]:\n",
    "                print(\"error for \" + name + \" for quantity 2\")\n",
    "            Data=r.json()\n",
    "            Data[\"note\"]=Data[\"note\"]+\" / \"+ Note\n",
    "            r=requests.patch(url + \"samples/\"+id, headers = headers2,data = Data)\n",
    "            if r.status_code not in [200,204]:\n",
    "                print(\"error for \" + name + \" for quantity 3\")\n",
    "print(\"finished\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618c10b9",
   "metadata": {},
   "source": [
    "### For Non indexed librairies\n",
    "We have not done any external tables. I just actualize the parent sample link!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811e67c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(url + \"sampleTypes/\" + types[\"Non Indexed Library\"] + \"/meta\", headers = headers2)\n",
    "data = r.json()\n",
    "FeateLabNiLib = {}\n",
    "for feat in ['Name','Description','Note','Amount','Unit',\"parentSampleID\"]:\n",
    "    FeateLabNiLib[feat] = {\"ID\": \"notMeta\"}\n",
    "for feat in data.get(\"data\"):\n",
    "    FeateLabNiLib[format(feat.get(\"key\"))] = { \"ID\":format(feat.get(\"sampleTypeMetaID\")),\n",
    "                                              \"TYPE\":format(feat.get(\"sampleDataType\"))}\n",
    "print(FeateLabNiLib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5cc32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###GET extract Name from library name\n",
    "def getExtract(libName):\n",
    "    ret=libName[0]\n",
    "    for char in libName[1:(len(libName)-2)]:\n",
    "        ret=ret+char\n",
    "    return(ret)\n",
    "\n",
    "\n",
    "for niLib in registered[\"Non Indexed Library\"].keys():\n",
    "    #print(niLib)\n",
    "    id=registered[\"Non Indexed Library\"][niLib]\n",
    "    #retrieve data\n",
    "    DR=requests.get(url + \"samples/\"+id, headers = headers2)\n",
    "    if DR.status_code not in [200]:\n",
    "        print(\"error retrieving \" + niLib)\n",
    "        print(DR.status_code)\n",
    "        print(DR.raise_for_status())\n",
    "        break\n",
    "    Data=DR.json()\n",
    "    extract=None\n",
    "    idExtract=None\n",
    "    if niLib.startswith(\"BL\"):\n",
    "        MDR=requests.get(url + \"samples/\"+id+\"/meta/\", headers = headers2)\n",
    "        ####check the MetaData loading was correct\n",
    "        if MDR.status_code not in [200,204]:\n",
    "            print(\"error retrieving from extract for \" + niLib)\n",
    "            print(MDR.status_code)\n",
    "            print(MDR.raise_for_status())\n",
    "            break\n",
    "        data=MDR.json().get(\"data\")\n",
    "        for dd in data:\n",
    "            if dd[\"key\"] == \"From Extract\":\n",
    "                extract=dd[\"value\"].split(\"|\")[0]\n",
    "    else:\n",
    "        extract=getExtract(niLib)\n",
    "    if extract is None:\n",
    "        print(\"extract not retrieve\")\n",
    "        break\n",
    "    idExtract=registered[\"Extract\"][extract]\n",
    "    \n",
    "    ###parent sample:\n",
    "    Data[\"parentSampleID\"]=idExtract\n",
    "    DR=requests.patch(url + \"samples/\"+id, headers = headers2,data=Data)\n",
    "    if DR.status_code not in [200,204]:\n",
    "        print(\"error patching\" + niLib)\n",
    "        print(DR.status_code)\n",
    "        print(DR.raise_for_status())\n",
    "        break\n",
    "        \n",
    "    ###From extract\n",
    "    element=extract+\"|\"+idExtract\n",
    "    samples={\"sampleID\": idExtract,\"name\": extract}\n",
    "    MetaData={\n",
    "        \"sampleTypeMetaID\": int(FeateLabNiLib[\"From Extract\"]['ID']),\n",
    "        \"sampleDataType\": FeateLabNiLib[\"From Extract\"]['TYPE'],\n",
    "        \"samples\": samples,\n",
    "        \"key\": \"From Extract\",\n",
    "        \"value\": element\n",
    "    }\n",
    "    MDR=requests.put(url + \"samples/\"+id+\"/meta\", headers = headers2,data = MetaData)\n",
    "    ####check the MetaData loading was correct\n",
    "    if MDR.status_code not in [200,204]:\n",
    "        print(\"error retrieving meta for \" + niLib)\n",
    "        print(MDR.status_code)\n",
    "        print(MDR.raise_for_status())\n",
    "        break\n",
    "print(\"finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0eaae5",
   "metadata": {},
   "source": [
    "### Indexed library\n",
    "Same: we just actualize the links to Non Indexed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe47136",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "r = requests.get(url + \"sampleTypes/\" + types[\"Indexed Library\"] + \"/meta\", headers = headers2)\n",
    "data = r.json()\n",
    "FeateLabILib = {}\n",
    "for feat in ['Name','Description','Note','Amount','Unit',\"parentSampleID\"]:\n",
    "    FeateLabILib[feat] = {\"ID\": \"notMeta\"}\n",
    "for feat in data.get(\"data\"):\n",
    "    FeateLabILib[format(feat.get(\"key\"))] = { \"ID\":format(feat.get(\"sampleTypeMetaID\")),\n",
    "                                              \"TYPE\":format(feat.get(\"sampleDataType\"))}\n",
    "print(FeateLabILib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da8f3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ILib in registered[\"Indexed Library\"].keys():\n",
    "    #print(ILib)\n",
    "    id=registered[\"Indexed Library\"][ILib]\n",
    "    #retrieve data\n",
    "    DR=requests.get(url + \"samples/\"+id, headers = headers2)\n",
    "    if DR.status_code not in [200]:\n",
    "        print(\"error retrieving \" + niLib)\n",
    "        print(DR.status_code)\n",
    "        print(DR.raise_for_status())\n",
    "        break\n",
    "    Data=DR.json()\n",
    "    niLib=None\n",
    "    idniLib=None\n",
    "    MDR=requests.get(url + \"samples/\"+id+\"/meta/\", headers = headers2)\n",
    "    ####check the MetaData loading was correct\n",
    "    if MDR.status_code not in [200,204]:\n",
    "        print(\"error retrieving from extract for \" + ILib)\n",
    "        print(MDR.status_code)\n",
    "        print(MDR.raise_for_status())\n",
    "        break\n",
    "    data=MDR.json().get(\"data\")\n",
    "    for dd in data:\n",
    "        if dd[\"key\"] == \"From Non Indexed Library\":\n",
    "            niLib=dd[\"value\"].split(\"|\")[0]\n",
    "    if niLib is None:\n",
    "        print(\"Non indexed Library not retrieve\")\n",
    "        break\n",
    "    idniLib=registered[\"Non Indexed Library\"][niLib]\n",
    "    \n",
    "    ###parent sample:\n",
    "    Data[\"parentSampleID\"]=idniLib\n",
    "    DR=requests.patch(url + \"samples/\"+id, headers = headers2,data=Data)\n",
    "    if DR.status_code not in [200,204]:\n",
    "        print(\"error patching\" + ILib)\n",
    "        print(DR.status_code)\n",
    "        print(DR.raise_for_status())\n",
    "        break\n",
    "        \n",
    "    ###From extract\n",
    "    element=niLib+\"|\"+idniLib\n",
    "    samples={\"sampleID\": idniLib,\"name\": niLib}\n",
    "    MetaData={\n",
    "        \"sampleTypeMetaID\": int(FeateLabILib[\"From Non Indexed Library\"]['ID']),\n",
    "        \"sampleDataType\": FeateLabILib[\"From Non Indexed Library\"]['TYPE'],\n",
    "        \"samples\": samples,\n",
    "        \"key\": \"From Non Indexed Library\",\n",
    "        \"value\": element\n",
    "    }\n",
    "    MDR=requests.put(url + \"samples/\"+id+\"/meta\", headers = headers2,data = MetaData)\n",
    "    ####check the MetaData loading was correct\n",
    "    if MDR.status_code not in [200,204]:\n",
    "        print(\"error retrieving meta for \" + ILib)\n",
    "        print(MDR.status_code)\n",
    "        print(MDR.raise_for_status())\n",
    "        break\n",
    "print(\"finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b39cf5",
   "metadata": {},
   "source": [
    "## Sample assignation to Experiments\n",
    "\n",
    "first retrieve the eLab ID needed to access the sampleIN and sampleOUT sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99134c9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "r = requests.get(url + \"experiments\", headers = headers2,params = params)\n",
    "data = r.json()\n",
    "experiments = {}\n",
    "for exp in data.get(\"data\"):\n",
    "    experiments[format(exp.get(\"name\"))] = format(exp.get(\"experimentID\"))\n",
    "\n",
    "\n",
    "\n",
    "for expe in list(experiments.keys()):\n",
    "    #print(expe)\n",
    "    idExpe=experiments[expe]\n",
    "    r=requests.get(\"https://elab-dev.pasteur.fr/api/v1/experiments/\"+idExpe+\"/sections\",headers=headers1)\n",
    "    if r.status_code != 200:\n",
    "        print(r.status_code)\n",
    "        print(r.raise_for_status())\n",
    "    if r.json().get(\"recordCount\") == 0:\n",
    "        print(\"no record\")\n",
    "        continue\n",
    "    SampleIN={}\n",
    "    SampleOUT={}\n",
    "    for data in r.json().get(\"data\"):\n",
    "        if data[\"sectionType\"] == \"SAMPLESIN\":\n",
    "            SampleIN[data[\"sectionHeader\"]]=data[\"expJournalID\"]\n",
    "        elif data[\"sectionType\"] == \"SAMPLESOUT\":\n",
    "            SampleOUT[data[\"sectionHeader\"]]=data[\"expJournalID\"]\n",
    "    experiments[expe]={\"ID\":idExpe,\n",
    "                      \"sampleIN\":SampleIN,\n",
    "                      \"sampleOUT\":SampleOUT}\n",
    "#print(experiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc278720",
   "metadata": {},
   "source": [
    "### Assign to Labelling sampleIN the individuals and to Labelling sampleOUT the skeleton elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c18fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleOUT=experiments[\"Labelling process\"][\"sampleOUT\"][\"Labelled Skeleton elements \"]\n",
    "sampleIN=experiments[\"Labelling process\"][\"sampleIN\"][\"Individuals labelled\"]\n",
    "\n",
    "listOUT=[]\n",
    "listIN=[]\n",
    "for inName in registered[\"Skeleton Element\"].keys():\n",
    "    inID=registered[\"Skeleton Element\"][inName]\n",
    "    listOUT.append(inID)\n",
    "    ###get the parent individual\n",
    "    r=requests.get(url+\"/samples/\"+inID+\"/parent\",headers=headers1)\n",
    "    if r.status_code !=200:\n",
    "        print(r.status_code)\n",
    "        r.raise_for_status()\n",
    "        break\n",
    "    rjson=r.json()\n",
    "    outName=rjson.get(\"name\")\n",
    "    listIN.append(rjson.get(\"sampleID\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280a86c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "listOUT=format(listOUT)\n",
    "#print(listOUT)\n",
    "r=requests.put(url+\"/experiments/sections/\"+format(sampleOUT)+\"/samples\",headers=headers1,data = listOUT)\n",
    "if r.status_code !=204:\n",
    "    print(r.status_code)\n",
    "    r.raise_for_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98a27ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "listIN=format(listIN)\n",
    "r=requests.put(url+\"/experiments/sections/\"+format(sampleIN)+\"/samples\",headers=headers1,data = listIN)\n",
    "if r.status_code !=204:\n",
    "    print(r.status_code)\n",
    "    r.raise_for_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4724586f",
   "metadata": {},
   "source": [
    "### Assign to Drilling Rasovan Laboratory Protocols\n",
    "\"pulverized pieces\" (sampleIN) and  the skeleton elements they derive from (sampleOUT), all extracts that appear in \"DDBB_extract.csv\"\n",
    "\n",
    "\n",
    "Starts with retrieving all field IDs required for that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5361c8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the sampleIN and sampleOUT id for the experiment\n",
    "CorresExtract={\"petrous\":\"Pulverized petrous bone\",\n",
    "                  \"dental calculus\":\"Scratched Dental Calculus\",\n",
    "                  \"pulp\":\"Pulverized Pulp\",\n",
    "                  \"root\":\"Pulverized Root\",\n",
    "                   \"root apex\":\"Pulverized Root Apex\",\n",
    "                  \"long bone\":\"Pulverized long bone\",\n",
    "                    \"other\":\"Pulverized other bone\",\n",
    "              }\n",
    "CorresSkel={\"Petrous\":\"Petrous bone processed\",\n",
    "            \"Tooth\":\"Tooth processed\",\n",
    "            \"Other Bone\":\"Long bone processed \"}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17d6757",
   "metadata": {},
   "source": [
    "Now we get extract and skeleton element ID and we assign them to different experiment (according to some in-house conditions:\n",
    " - name starting with NR means they were processed by Nico at Schroeder lab\n",
    " - expediente is \"Guareib / Pulverized\" means we already received the pulverized pieces\n",
    " - the skeleton element is Dental calculus means Mariano del Papa sent us the scratched dental calculus\n",
    " - else it it our own protocoles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166d08f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "listOUT={}\n",
    "listIN={}\n",
    "for lab in [\"Guraeib\",\"Del Papa\",\"Schroeder\",\"Rascovan\"]:\n",
    "    listOUT[lab]={}\n",
    "    listIN[lab]={}\n",
    "    for exType in CorresExtract:\n",
    "        listOUT[lab][CorresExtract[exType]]=[]\n",
    "\n",
    "    for skelType in CorresSkel:\n",
    "        listIN[lab][CorresSkel[skelType]]=[]\n",
    "\n",
    "for index, extract in extractTable[\"ExtractID\"].items():\n",
    "    if extract.startswith(\"Blank\"):\n",
    "        continue\n",
    "    ###prepare sampleOUT for that extract\n",
    "    idOUT=registered[\"Extract\"][extract]\n",
    "    #get meta \n",
    "    MER=requests.get(url+\"/samples/\"+idOUT+\"/meta\",headers=headers1)\n",
    "    if MER.status_code !=200:\n",
    "        print(MER.raise_for_status())\n",
    "        break\n",
    "    #get Extract Type and check it is found\n",
    "    exType=None\n",
    "    for meta in MER.json().get(\"data\"):\n",
    "        if meta[\"key\"]==\"Extract Type\":\n",
    "            exType=meta[\"value\"]\n",
    "            break\n",
    "    if exType is None:\n",
    "        print(\"Extract Type not found\")\n",
    "        break\n",
    "    ###prepare sampleIN for that extract\n",
    "    #get parentSampleID (the skeleton element)\n",
    "    ER=requests.get(url+\"/samples/\"+idOUT,headers=headers1)\n",
    "    if ER.status_code !=200:\n",
    "        print(ER.raise_for_status())\n",
    "        break\n",
    "    idIN=format(ER.json()[\"parentSampleID\"])\n",
    "\n",
    "    #get meta\n",
    "    SMR=requests.get(url+\"/samples/\"+idIN+\"/meta\",headers=headers1)\n",
    "    if SMR.status_code !=200:\n",
    "        print(SMR.raise_for_status())\n",
    "        break\n",
    "    ##get skeleton element type and check it is found\n",
    "    archoID=None\n",
    "    skelType=None\n",
    "    expediente=None\n",
    "    for meta in SMR.json().get(\"data\"):\n",
    "        if meta[\"key\"]==\"Bone type\":\n",
    "            skelType=meta[\"value\"]\n",
    "        elif meta[\"key\"]==\"Exportation Permit Number\":\n",
    "            expediente=meta[\"value\"]\n",
    "        elif meta[\"key\"]==\"Archaeologist sample ID\":\n",
    "            archoID=meta[\"value\"]\n",
    "    if skelType is None:\n",
    "        print(\"Skeleton Ele Type not found\")\n",
    "        print(SMR.json().get(\"data\"))\n",
    "        break\n",
    "    if expediente is None:\n",
    "        print(\"Expediente not found\")\n",
    "        print(SMR.json().get(\"data\"))\n",
    "        break\n",
    "    if archoID is None:\n",
    "        print(\"archeo ID not found\")\n",
    "        print(SMR.json().get(\"data\"))\n",
    "        break\n",
    "\n",
    "    if skelType == \"Dental Calculus\":\n",
    "        #print(\"del Papa\")\n",
    "        listOUT[\"Del Papa\"][CorresExtract[exType]].append(idOUT)\n",
    "    elif expediente==\"Solana Guraeib / Pulverized\":\n",
    "        #print(\"Guareib\")\n",
    "        listOUT[\"Guraeib\"][CorresExtract[exType]].append(idOUT)\n",
    "        listIN[\"Guraeib\"][CorresSkel[skelType]].append(idIN)\n",
    "    elif archoID.startswith(\"NR\"):\n",
    "        #print(\"Schroeder\")\n",
    "        listOUT[\"Schroeder\"][CorresExtract[exType]].append(idOUT)\n",
    "        listIN[\"Schroeder\"][CorresSkel[skelType]].append(idIN)\n",
    "    else:\n",
    "        #print(\"Rascovan\")\n",
    "        listOUT[\"Rascovan\"][CorresExtract[exType]].append(idOUT)\n",
    "        listIN[\"Rascovan\"][CorresSkel[skelType]].append(idIN)\n",
    "        \n",
    "\n",
    "print(listIN)\n",
    "print(listOUT)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f592aacf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###upload sample IN\n",
    "for lab in [\"Guraeib\",\"Del Papa\",\"Schroeder\",\"Rascovan\"]:\n",
    "    for type in listIN[lab].keys():\n",
    "        data=listIN[lab][type]\n",
    "        if len(data)==0:\n",
    "            print(\"sample IN : nothing to upload upload for \"+type+\" to \"+lab)\n",
    "        else:\n",
    "            idIN=format(experiments[\"Drilling. \"+lab+\" Laboratory Protocols\"][\"sampleIN\"][type])\n",
    "            print(\"sample IN : upload for \"+type+\" to \"+lab)\n",
    "            data=format(data)\n",
    "            r=requests.put(url+\"/experiments/sections/\"+idIN+\"/samples\",headers=headers1,data = data)\n",
    "            if r.status_code !=204:\n",
    "                print(r.status_code)\n",
    "                r.raise_for_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702725f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###upload sample OUT\n",
    "for lab in [\"Guraeib\",\"Del Papa\",\"Schroeder\",\"Rascovan\"]:\n",
    "    for type in listOUT[lab].keys():\n",
    "        data=listOUT[lab][type]\n",
    "        if len(data)==0:\n",
    "            print(\"sample OUT : nothing to upload upload for \"+type+\" to \"+lab)\n",
    "        else:\n",
    "            idOUT=format(experiments[\"Drilling. \"+lab+\" Laboratory Protocols\"][\"sampleOUT\"][type])\n",
    "            print(\"sample OUT : upload for \"+type+\" to \"+lab)\n",
    "            data=format(data)\n",
    "            r=requests.put(url+\"/experiments/sections/\"+idOUT+\"/samples\",headers=headers1,data = data)\n",
    "            if r.status_code !=204:\n",
    "                print(r.status_code)\n",
    "                r.raise_for_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd2539f",
   "metadata": {},
   "source": [
    "### Experiment: Extraction. Rascovan Laboratory Protocols\n",
    "Now we add in \"as sampleIN and sampleOUT the \"pulverized bone\" for which there is an non-indexed library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b27e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "listIN=[]\n",
    "for lib,libID in registered[\"Non Indexed Library\"].items():\n",
    "    r=requests.get(url+\"/samples/\"+libID,headers=headers1)\n",
    "    if r.status_code !=200:\n",
    "        print(r.status_code)\n",
    "        print(r.raise_for_status())\n",
    "        break\n",
    "    extID=r.json().get(\"parentSampleID\")\n",
    "    r=requests.get(url+\"/samples/\"+format(extID),headers=headers1)\n",
    "    if r.status_code !=200:\n",
    "        print(r.status_code)\n",
    "        print(r.raise_for_status())\n",
    "        break\n",
    "    ext=r.json().get(\"name\")\n",
    "    if ext.startswith(\"Blank\"):\n",
    "        date=\"\".join(ext.split(\".\")[1].split(\"-\")[::-1])\n",
    "        if lib !=\"BL\"+date+\"00\":\n",
    "            print(\"HU? \"+ext+\" for \"+lib)\n",
    "            break\n",
    "    elif ext+\"00\" != lib:\n",
    "        print(\"HU? \"+ext+\" for \"+lib)\n",
    "        print(ext)\n",
    "        break\n",
    "    listIN.append(extID)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32b5905",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=format(listIN)\n",
    "###assign to sampleIN\n",
    "idExp={\"c\":str(value) for key, value in experiments[\"Extraction. Rascovan Lab Protocols\"][\"sampleIN\"].items()}[\"c\"]\n",
    "print(idExp)\n",
    "r=requests.put(url+\"/experiments/sections/\"+idExp+\"/samples\",headers=headers1,data = data)\n",
    "print(r)\n",
    "###assign to sampleOUT\n",
    "idExp={\"c\":str(value) for key, value in experiments[\"Extraction. Rascovan Lab Protocols\"][\"sampleOUT\"].items()}[\"c\"]\n",
    "print(idExp)\n",
    "r=requests.put(url+\"/experiments/sections/\"+idExp+\"/samples\",headers=headers1,data = data)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2654542f",
   "metadata": {},
   "source": [
    "### Experiment: Library Prep. Rascovan Lab protocols\n",
    "Now we add in \"as sampleIN \"pulverized bone\" for which there is an \"indexed library\" and as sampleOUT that indexed library and the corresponding non indexed library\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c0cc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "extIN=[]\n",
    "nonIndLibOUT=[]\n",
    "indLibOUT=[]\n",
    "for indLib,indLibID in registered[\"Indexed Library\"].items():\n",
    "    \n",
    "    ###retrieve the non Index Librar info\n",
    "    r=requests.get(url+\"/samples/\"+indLibID,headers=headers1)\n",
    "    if r.status_code !=200:\n",
    "        print(r.status_code)\n",
    "        print(r.raise_for_status())\n",
    "        break\n",
    "    nonIndLibID=r.json().get(\"parentSampleID\")\n",
    "    r=requests.get(url+\"/samples/\"+format(nonIndLibID),headers=headers1)\n",
    "    if r.status_code !=200:\n",
    "        print(r.status_code)\n",
    "        print(r.raise_for_status())\n",
    "        break\n",
    "    nonIndLib=r.json().get(\"name\")\n",
    "    ###check inIndLib ifinished with 0\n",
    "    if nonIndLib[-1] !=\"0\":\n",
    "        print(\"hu \"+nonIndLib)\n",
    "        break\n",
    "    ###check nonIndLib and IndLib corresponds\n",
    "    if ''.join(nonIndLib[0:(len(nonIndLib)-2)]) != ''.join(indLib[0:(len(indLib)-2)]):\n",
    "        print(\"HU? \"+indLib+\" \"+nonIndLib)\n",
    "        break\n",
    "        \n",
    "        \n",
    "    ###retrieve the extract \n",
    "    extID=r.json().get(\"parentSampleID\")\n",
    "    r=requests.get(url+\"/samples/\"+format(extID),headers=headers1)\n",
    "    if r.status_code !=200:\n",
    "        print(r.status_code)\n",
    "        print(r.raise_for_status())\n",
    "        break\n",
    "    ext=r.json().get(\"name\")\n",
    "    ##check extract corresponds to non indexed library\n",
    "    if ext.startswith(\"Blank\"):\n",
    "        date=\"\".join(ext.split(\".\")[1].split(\"-\")[::-1])\n",
    "        if nonIndLib !=\"BL\"+date+\"00\":\n",
    "            print(\"HU? \"+ext+\" for \"+nonIndLib)\n",
    "            break\n",
    "    elif ext+\"00\" != nonIndLib:\n",
    "        print(\"HU? \"+ext+\" for \"+nonIndLib)\n",
    "        print(ext)\n",
    "        break\n",
    "    \n",
    "    extIN.append(extID)\n",
    "    nonIndLibOUT.append(nonIndLibID)\n",
    "    indLibOUT.append(indLibID)\n",
    "\n",
    "print(len(extIN))\n",
    "print(len(nonIndLibOUT))\n",
    "print(len(indLibOUT))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e804d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "###assign to sampleIN extracts\n",
    "idExp={\"c\":str(value) for key, value in experiments[\"Library Prep. Rascovan Lab protocols\"][\"sampleIN\"].items()}[\"c\"]\n",
    "print(idExp)\n",
    "data=format(extIN)\n",
    "r=requests.put(url+\"/experiments/sections/\"+idExp+\"/samples\",headers=headers1,data = data)\n",
    "print(r)\n",
    "\n",
    "###assign to sampleOUT non indexed Library\n",
    "idExp=experiments[\"Library Prep. Rascovan Lab protocols\"][\"sampleOUT\"][\"UDG-treated extracts\"]\n",
    "print(idExp)\n",
    "data=format(nonIndLibOUT)\n",
    "r=requests.put(url+\"/experiments/sections/\"+format(idExp)+\"/samples\",headers=headers1,data = data)\n",
    "print(r)\n",
    "\n",
    "\n",
    "###assign to sampleOUT indexed Library\n",
    "idExp=experiments[\"Library Prep. Rascovan Lab protocols\"][\"sampleOUT\"][\"Library generated\"]\n",
    "print(idExp)\n",
    "data=format(indLibOUT)\n",
    "r=requests.put(url+\"/experiments/sections/\"+format(idExp)+\"/samples\",headers=headers1,data = data)\n",
    "print(r)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27b6fad",
   "metadata": {},
   "source": [
    "### Check if all samples in eLab are assigned to an experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbee7e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def condition(name,listToCheck):\n",
    "    return name not in listToCheck\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ed69fd",
   "metadata": {},
   "source": [
    "### For Labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26da8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "###check if all individuals as sampleIN for labelling process\n",
    "r=requests.get(url+\"/experiments/sections/\"+format(experiments[\"Labelling process\"][\"sampleIN\"][\"Individuals labelled\"])+\"/samples\",headers=headers2)\n",
    "listInExp=[]\n",
    "for i in r.json().get(\"data\"):\n",
    "    listInExp.append(i[\"name\"])\n",
    "\n",
    "IndnotInLabelling=[element for idx,element in enumerate(registered[\"Individual\"]) if condition(element,listInExp)]\n",
    "print(IndnotInLabelling)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9362601",
   "metadata": {},
   "outputs": [],
   "source": [
    "###check if all Skeleton element  as sampleOUT for labelling process\n",
    "r=requests.get(url+\"/experiments/sections/\"+format(experiments[\"Labelling process\"][\"sampleOUT\"][\"Labelled Skeleton elements \"])+\"/samples\",headers=headers1)\n",
    "listInExp=[]\n",
    "for i in r.json().get(\"data\"):\n",
    "    listInExp.append(i[\"name\"])\n",
    "\n",
    "SkelnotInLabelling=[element for idx,element in enumerate(registered[\"Skeleton Element\"]) if condition(element,listInExp)]\n",
    "print(SkelnotInLabelling)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f769e37",
   "metadata": {},
   "source": [
    "### For Drilling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce4805e",
   "metadata": {},
   "outputs": [],
   "source": [
    "listInExp=[]\n",
    "###check if all skeleton element as sampleIN for drilling processes\n",
    "for key in experiments.keys():\n",
    "    if not key.startswith(\"Drilling\"):\n",
    "        continue\n",
    "    for inty in experiments[key][\"sampleIN\"]:\n",
    "        r=requests.get(url+\"/experiments/sections/\"+format(experiments[key][\"sampleIN\"][inty])+\"/samples\",headers=headers1)\n",
    "        if r.status_code!=200:\n",
    "            print(key+\" \"+inty+\" bad request\")\n",
    "            break\n",
    "        for i in r.json().get(\"data\"):\n",
    "            if i[\"name\"] in listInExp:\n",
    "                print(i[\"name\"]+\" assigned to different drilling processes\")\n",
    "            else:\n",
    "                listInExp.append(i[\"name\"])\n",
    "                \n",
    "notDrilled=[element for idx,element in enumerate(registered[\"Skeleton Element\"]) if condition(element,listInExp)]\n",
    "print(format(len(notDrilled))+ \" skel element not drilled\")\n",
    "Drilled=[element for idx,element in enumerate(registered[\"Skeleton Element\"]) if not condition(element,listInExp)]\n",
    "print(format(len(Drilled))+ \" skel element drilled\")\n",
    "\n",
    "\n",
    "        \n",
    "            \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0189dc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "listInExp=[]\n",
    "###check if all extracts as sampleOUT for drilling processes\n",
    "for key in experiments.keys():\n",
    "    if not key.startswith(\"Drilling\"):\n",
    "        continue\n",
    "    for inty in experiments[key][\"sampleOUT\"]:\n",
    "        r=requests.get(url+\"/experiments/sections/\"+format(experiments[key][\"sampleOUT\"][inty])+\"/samples\",headers=headers1)\n",
    "        if r.status_code!=200:\n",
    "            print(key+\" \"+inty+\" bad request\")\n",
    "            break\n",
    "        for i in r.json().get(\"data\"):\n",
    "            if i[\"name\"] in listInExp:\n",
    "                print(i[\"name\"]+\" assigned to different drilling processes\")\n",
    "            else:\n",
    "                listInExp.append(i[\"name\"])\n",
    "                \n",
    "notDrilled=[element for idx,element in enumerate(registered[\"Extract\"]) if condition(element,listInExp)]\n",
    "print(format(len(notDrilled))+ \" extracts not assigned to drilling\")\n",
    "print(notDrilled)\n",
    "Drilled=[element for idx,element in enumerate(registered[\"Extract\"]) if not condition(element,listInExp)]\n",
    "print(format(len(Drilled))+ \" extracts assigned to drilling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de6809a",
   "metadata": {},
   "source": [
    "### For extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a79a8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "listInExp=[]\n",
    "###check if all extracts as sampleIN for extraction\n",
    "for key in experiments.keys():\n",
    "    if not key.startswith(\"Extraction\"):\n",
    "        continue\n",
    "    for inty in experiments[key][\"sampleIN\"]:\n",
    "        r=requests.get(url+\"/experiments/sections/\"+format(experiments[key][\"sampleIN\"][inty])+\"/samples\",headers=headers1)\n",
    "        if r.status_code!=200:\n",
    "            print(key+\" \"+inty+\" bad request\")\n",
    "            break\n",
    "        for i in r.json().get(\"data\"):\n",
    "            if i[\"name\"] in listInExp:\n",
    "                print(i[\"name\"]+\" assigned to different extraction  processes\")\n",
    "            else:\n",
    "                listInExp.append(i[\"name\"])\n",
    "                \n",
    "notExtractedIN=[element for idx,element in enumerate(registered[\"Extract\"]) if condition(element,listInExp)]\n",
    "print(format(len(notExtractedIN))+ \" pulverized pieces not assigned to extraction as IN\")\n",
    "ExtractedIN=[element for idx,element in enumerate(registered[\"Extract\"]) if not condition(element,listInExp)]\n",
    "print(format(len(ExtractedIN))+ \" pulverized pieces assigned to extraction as IN\")\n",
    "\n",
    "#check if all extracted pieces has been drilled\n",
    "ExtractedNotDrilled=[element for idx,element in enumerate(ExtractedIN) if condition(element,Drilled)]\n",
    "print(format(len(ExtractedNotDrilled))+ \" pulverized pieces assigned to extraction but not Drilling\")\n",
    "print(ExtractedNotDrilled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0bcbd6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "listInExp=[]\n",
    "#check if all extracts (ARXXXX.Y.ZZ) assigned to Extraction as sampleOUT\n",
    "for key in experiments.keys():\n",
    "    if not key.startswith(\"Extraction\"):\n",
    "        continue\n",
    "    for inty in experiments[key][\"sampleOUT\"]:\n",
    "        r=requests.get(url+\"/experiments/sections/\"+format(experiments[key][\"sampleOUT\"][inty])+\"/samples\",headers=headers1)\n",
    "        if r.status_code!=200:\n",
    "            print(key+\" \"+inty+\" bad request\")\n",
    "            break\n",
    "        for i in r.json().get(\"data\"):\n",
    "            if i[\"name\"] in listInExp:\n",
    "                print(i[\"name\"]+\" assigned to different extraction  processes\")\n",
    "            else:\n",
    "                listInExp.append(i[\"name\"])\n",
    "                \n",
    "notExtractedOUT=[element for idx,element in enumerate(registered[\"Extract\"]) if condition(element,listInExp)]\n",
    "print(format(len(notExtractedOUT))+ \" pulverized pieces not assigned to extraction as OUT\")\n",
    "ExtractedOUT=[element for idx,element in enumerate(registered[\"Extract\"]) if not condition(element,listInExp)]\n",
    "print(format(len(ExtractedOUT))+ \" pulverized pieces assigned to extraction as OUT\")\n",
    "\n",
    "#check if all extracted as IN are as OUT\n",
    "ExtractedOUTNotIN=[element for idx,element in enumerate(ExtractedOUT) if condition(element,ExtractedIN)]\n",
    "print(format(len(ExtractedOUTNotIN))+ \" pulverized pieces assigned to extraction as OUT but not as IN\")\n",
    "\n",
    "#check if all extracted as OUT are as IN\n",
    "ExtractedINNotOUT=[element for idx,element in enumerate(ExtractedIN) if condition(element,ExtractedOUT)]\n",
    "print(format(len(ExtractedINNotOUT))+ \" pulverized pieces assigned to extraction as IN but not as OUT\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980e92d6",
   "metadata": {},
   "source": [
    "### Library PREP!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289afc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "listInExp=[]\n",
    "###check if all extracts as sampleIN for library prep\n",
    "for key in experiments.keys():\n",
    "    if not key.startswith(\"Library Prep\"):\n",
    "        continue\n",
    "    for inty in experiments[key][\"sampleIN\"]:\n",
    "        r=requests.get(url+\"/experiments/sections/\"+format(experiments[key][\"sampleIN\"][inty])+\"/samples\",headers=headers1)\n",
    "        if r.status_code!=200:\n",
    "            print(key+\" \"+inty+\" bad request\")\n",
    "            break\n",
    "        for i in r.json().get(\"data\"):\n",
    "            if i[\"name\"] in listInExp:\n",
    "                print(i[\"name\"]+\" assigned to different Lib Prep processes\")\n",
    "            else:\n",
    "                listInExp.append(i[\"name\"])\n",
    "                \n",
    "notLibPrepIN=[element for idx,element in enumerate(registered[\"Extract\"]) if condition(element,listInExp)]\n",
    "print(format(len(notLibPrepIN))+ \" pulverized pieces not assigned to Lib Prep as IN\")\n",
    "LibPrepIN=[element for idx,element in enumerate(registered[\"Extract\"]) if not condition(element,listInExp)]\n",
    "print(format(len(LibPrepIN))+ \" pulverized pieces assigned to Lib Prep as IN\")\n",
    "\n",
    "#check if all extraction as OUT in extract are as IN in LibPrep\n",
    "ExtractedOUTNotLipPrep=[element for idx,element in enumerate(ExtractedOUT) if condition(element,LibPrepIN)]\n",
    "print(format(len(ExtractedOUTNotLipPrep))+ \" pulverized pieces assigned to extraction as OUT but not as IN in LibPrep\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f86adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "listInExp=[]\n",
    "###check if all Non Indexed libraries as sampleOUT for library prep\n",
    "for key in experiments.keys():\n",
    "    if not key.startswith(\"Library Prep\"):\n",
    "        continue\n",
    "    for inty in experiments[key][\"sampleOUT\"]:\n",
    "        if not inty.startswith(\"UDG\"):\n",
    "            continue\n",
    "        print(inty)\n",
    "        r=requests.get(url+\"/experiments/sections/\"+format(experiments[key][\"sampleOUT\"][inty])+\"/samples\",headers=headers1)\n",
    "        if r.status_code!=200:\n",
    "            print(key+\" \"+inty+\" bad request\")\n",
    "            break\n",
    "        for i in r.json().get(\"data\"):\n",
    "            if i[\"name\"] in listInExp:\n",
    "                print(i[\"name\"]+\" assigned to different Lib Prep processes\")\n",
    "            else:\n",
    "                listInExp.append(i[\"name\"])\n",
    "            \n",
    "notNiLibPrepOUT=[element for idx,element in enumerate(registered[\"Non Indexed Library\"]) if condition(element,listInExp)]\n",
    "print(format(len(notNiLibPrepOUT))+ \" non indexed libraries not assigned to Lib Prep as OUT\")\n",
    "print(notNiLibPrepOUT)\n",
    "niLibPrepOUT=[element for idx,element in enumerate(registered[\"Non Indexed Library\"]) if not condition(element,listInExp)]\n",
    "print(format(len(niLibPrepOUT))+ \"non indexed libaries assigned to Lib Prep as OUT\")\n",
    "\n",
    "#check if all extraction as IN in extract correspond to non indexed lib as OUT in LibPrep\n",
    "LibPrepINcorres=[s + \"00\" for s in LibPrepIN]\n",
    "niLibPrepOUTNotLibPrepIN=[element for idx,element in enumerate(niLibPrepOUT) if condition(element,LibPrepINcorres)]\n",
    "print(format(len(niLibPrepOUTNotLibPrepIN))+ \" non indexed libraries with no correspondance in IN\")\n",
    "print(niLibPrepOUTNotLibPrepIN)\n",
    "#check if all indexed lib as OUT correspond to non indexed libs as IN in extract in LibPrep\n",
    "niLibPrepINNotLibPrepOUT=[element for idx,element in enumerate(LibPrepINcorres) if  condition(element,niLibPrepOUT)]\n",
    "print(format(len(niLibPrepINNotLibPrepOUT))+ \" indexed libraries with no correspondance for non indexed libraries\")\n",
    "print(niLibPrepINNotLibPrepOUT)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec2202a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "listInExp=[]\n",
    "###check if all Indexed libraries as sampleOUT for library prep\n",
    "for key in experiments.keys():\n",
    "    if not key.startswith(\"Library Prep\"):\n",
    "        continue\n",
    "    for inty in experiments[key][\"sampleOUT\"]:\n",
    "        if not inty.startswith(\"Library\"):\n",
    "            continue\n",
    "        r=requests.get(url+\"/experiments/sections/\"+format(experiments[key][\"sampleOUT\"][inty])+\"/samples\",headers=headers1)\n",
    "        if r.status_code!=200:\n",
    "            print(key+\" \"+inty+\" bad request\")\n",
    "            break\n",
    "        for i in r.json().get(\"data\"):\n",
    "            if i[\"name\"] in listInExp:\n",
    "                print(i[\"name\"]+\" assigned to different Lib Prep processes\")\n",
    "            else:\n",
    "                listInExp.append(i[\"name\"])\n",
    "            \n",
    "notLibPrepOUT=[element for idx,element in enumerate(registered[\"Indexed Library\"]) if condition(element,listInExp)]\n",
    "print(format(len(notLibPrepOUT))+ \" indexed libraries not assigned to Lib Prep as OUT\")\n",
    "print(notLibPrepOUT)\n",
    "LibPrepOUT=[element for idx,element in enumerate(registered[\"Indexed Library\"]) if not condition(element,listInExp)]\n",
    "print(format(len(LibPrepOUT))+ \" indexed libaries assigned to Lib Prep as OUT\")\n",
    "\n",
    "#check if all extraction as IN in extract correspond to indexed lib as OUT in LibPrep\n",
    "LibPrepINcorres=[s + \"01\" for s in LibPrepIN]\n",
    "LibPrepOUTNotLibPrepIN=[element for idx,element in enumerate(LibPrepOUT) if condition(element,LibPrepINcorres)]\n",
    "print(format(len(LibPrepOUTNotLibPrepIN))+ \"  indexed libraries with no correspondance in IN\")\n",
    "print(LibPrepOUTNotLibPrepIN)\n",
    "#check if all non indexed lib as OUT correspond to extraction as IN in extract in LibPrep\n",
    "LibPrepINNotLibPrepOUT=[element for idx,element in enumerate(LibPrepINcorres) if  condition(element,LibPrepOUT)]\n",
    "print(format(len(LibPrepINNotLibPrepOUT))+ \" indexed libraries with no correspondance in IN\")\n",
    "print(LibPrepINNotLibPrepOUT)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a272b9",
   "metadata": {},
   "source": [
    "## Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff603d16",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "storageByID={}\n",
    "r=requests.get(url+\"/storageLayers\",headers=headers1)\n",
    "stoData=r.json().get(\"data\")\n",
    "for sto in stoData:\n",
    "    storageByID[sto[\"storageLayerID\"]]={\"name\":sto[\"name\"],\"parentID\":sto[\"parentStorageLayerID\"]}\n",
    "    print(sto[\"name\"])\n",
    "def getParentSto(ID,stoDict):\n",
    "    if stoDict[ID][\"parentID\"]==0:\n",
    "        return(stoDict[ID][\"name\"])\n",
    "    else:\n",
    "        return(getParentSto(stoDict[ID][\"parentID\"],stoDict)+\", \"+stoDict[ID][\"name\"])\n",
    "    \n",
    "storage={}\n",
    "for stoID in storageByID.keys():\n",
    "    name=getParentSto(stoID,storageByID)\n",
    "    storage[name]=stoID\n",
    "    \n",
    "print(storage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadaa1c0",
   "metadata": {},
   "source": [
    "### Assign Individual to Individual artefactual Storage Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48458ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "for StoType in [\"Site\",\"Individual\"]:\n",
    "    IDsto=format(storage[StoType])\n",
    "    print(IDsto)\n",
    "    for key,id in registered[StoType].items():\n",
    "        r=requests.post(url+\"/samples/moveToLayer/\"+IDsto+\"?sampleIDs=\"+id,headers=headers1,data={})\n",
    "        if r.status_code != 204:\n",
    "            print(\"error for \"+key+\" \"+id)\n",
    "\n",
    "print(\"finished\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e267ef66",
   "metadata": {},
   "source": [
    "### assign Skeleton Element to some locations\n",
    "- those for which batch is A1, A2, B1, B2 or C are assigned to Copenhagen\n",
    "- those for which batch is Sequenced are assigned to Unkown\n",
    "- all the others are assigned to Nico office\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a1d61e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(table[\"1st Batch\"].value_counts())\n",
    "print(storage)\n",
    "for item,name in table[\"RascovanLabID\"].items():\n",
    "    id=registered[\"Skeleton Element\"][name]\n",
    "    if table[\"1st Batch\"][item] in [\"A1\",\"A2\",\"B1\",\"B2\",\"C\",\"Ready for DNA extraction\"]:\n",
    "        StoType=\"In Copenhagen\"\n",
    "    elif table[\"1st Batch\"][item] in [\"Sequenced\"]:\n",
    "        StoType=\"Unknown\"\n",
    "    elif format(table[\"1st Batch\"][item]) == \"nan\":\n",
    "        StoType=\"Nico office\"\n",
    "    else:\n",
    "        print(\"not recognized condition \"+format(table[\"1st Batch\"][item]))\n",
    "        break\n",
    "    IDsto=format(storage[StoType])\n",
    "    r=requests.post(url+\"/samples/moveToLayer/\"+IDsto+\"?sampleIDs=\"+id,headers=headers1,data={})\n",
    "    if r.status_code != 204:\n",
    "            print(\"error for \"+name+\" (\"+id+\")\")\n",
    "    \n",
    "print(\"finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97825c0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "for index,name in extractTable[ExeDict['Name']].items():\n",
    "    idEx=registered[\"Extract\"][name]\n",
    "    r=requests.get(url+\"/samples/get?sampleID=\"+idEx,headers=headers2)\n",
    "    if r.status_code != 200:\n",
    "            print(\"error GET for \"+name+\" (\"+idEx+\")\")\n",
    "            print(r.raise_for_status())\n",
    "    storedIn=r.json()[0][\"storageLayerID\"]\n",
    "    if storedIn != 0:\n",
    "        #print(name+\" already in some storage\")\n",
    "        continue\n",
    "    else:\n",
    "        freezer=extractTable[\"Freezer\"][index]\n",
    "        if format(freezer) in [\"To be spotted\",\"nan\"] :\n",
    "            freezer=\"Unknown\"\n",
    "        freezer=freezer.replace(\"Mariano Del Papa calculus to extract\",\"Mariano Del Papa calculus extraction\")\n",
    "        freezer=freezer.replace(\"A1+A2\",\"A1 + A2\")\n",
    "        freezer=freezer.replace(\"B1+B2\",\"B1 + B2\")\n",
    "        freezer=freezer.replace(\"sub-bag B1+B2 \",\"\")\n",
    "        freezer=freezer.replace(\"sub-bag B1 + B2 \",\"\")\n",
    "        freezer=freezer.replace(\"sub-bag \",\"\")\n",
    "        freezer=freezer.replace(\"pulps\",\"pulp\")\n",
    "        freezer=freezer.replace(\"roots\",\"root\")\n",
    "        freezer=freezer.replace(\" for back-up\",\" back-up\")\n",
    "        freezer=freezer.replace(\" for extraction\",\" extraction\")\n",
    "        freezer=freezer.replace(\" to extract\",\" extraction\")\n",
    "        freezer=freezer.replace(\"freezer\",\"Freezer\")\n",
    "        freezer=freezer.replace(\"Thomas\",\"Tom\")\n",
    "        freezer=freezer.replace(\"Hannes'\",\"Hannes\")\n",
    "        freezer=freezer.replace(\"Miren drawer\",\"Miren Drawer 2\")\n",
    "        freezer=freezer.replace(\"blue rack\",\"Blue Rack 1\")\n",
    "        freezer=freezer.replace(\", front extraction clean room 159\",\"\")\n",
    "        freezer=freezer.replace(\"bag C group sensitive, blue box (back-up)\",\"bag A1 + A2, C group sensitive, blue box, back-up\")\n",
    "        if freezer not in storage:\n",
    "            print(freezer+\" not registsred in eLab\")\n",
    "            break\n",
    "        IDsto=format(storage[freezer])\n",
    "        r=requests.post(url+\"/samples/moveToLayer/\"+IDsto+\"?sampleIDs=\"+idEx,headers=headers1,data={})\n",
    "        if r.status_code != 204:\n",
    "            print(\"error POST for \"+name+\" (\"+idEx+\")\")\n",
    "            print(r.raise_for_status())\n",
    "\n",
    "\n",
    "print(\"finished\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d14ea98",
   "metadata": {},
   "source": [
    "### Check samples without storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0d1e5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for type in registered:\n",
    "    print(type)\n",
    "    for name in registered[type]:\n",
    "        idTY=registered[type][name]\n",
    "        r=requests.get(url+\"/samples/get?sampleID=\"+idTY,headers=headers2)\n",
    "        if r.status_code != 200:\n",
    "            print(\"error GET for \"+name+\" (\"+idTY+\")\")\n",
    "            print(r.raise_for_status())\n",
    "        storedIn=r.json()[0][\"storageLayerID\"]\n",
    "        if storedIn == 0:\n",
    "            print(name+\" NO storage\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614b07d4",
   "metadata": {},
   "source": [
    "## Some Play Around with the Data Base\n",
    "### get ends points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99745dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursiveChildren(name,level):\n",
    "    levelSeq=[\"Site\",\"Individual\",\"Skeleton Element\",\n",
    "              \"Extract\",\"Non Indexed Library\",\"Indexed Library\",\"Library Pool\"]\n",
    "    levelName=levelSeq[level]\n",
    "    id=registered[levelName][name]\n",
    "    r=requests.get(url+\"/samples/\"+id+\"/children\",headers=headers2)\n",
    "    json=r.json()\n",
    "    num=json.get(\"recordCount\")\n",
    "    print(''.join([char*level for char in \"\\t\"])+\"- \"+\n",
    "          levelName+\" \\\"\"+name+\"\\\": \"+format(num)+\" \"+levelSeq[level+1])\n",
    "    if num > 0:\n",
    "        level=level+1\n",
    "        data=json.get(\"data\")\n",
    "        ch=-1\n",
    "        while ch < (num-1):\n",
    "            ch+=1\n",
    "            nameCh=data[ch][\"name\"]\n",
    "            recursiveChildren(nameCh,level)\n",
    "    else:\n",
    "        level-=level\n",
    "    if level<0:\n",
    "        return(None)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235b0e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Site=\"El Alto\"\n",
    "id=registered[\"Site\"][Site]\n",
    "recursiveChildren(Site,0)\n",
    "\n",
    "print(\"Other Test\")\n",
    "Indi=\"AR0025\"\n",
    "id=registered[\"Individual\"][Indi]\n",
    "recursiveChildren(Indi,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b392fd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursiveParent(name,level):\n",
    "    levelSeq=['Library Pool', 'Indexed Library', 'Non Indexed Library', 'Extract',\n",
    "              'Skeleton Element', 'Individual', 'Site']\n",
    "    levelName=levelSeq[level]\n",
    "    id=registered[levelName][name]\n",
    "    r=requests.get(url+\"/samples/\"+id+\"/parent\",headers=headers2)\n",
    "    json=r.json()\n",
    "    nameP=json.get(\"name\")\n",
    "    print(name+\" (\"+levelName+\")\\n|\\nV\")\n",
    "    if nameP is None:\n",
    "        print(\"Endpoint\")\n",
    "        return(None)\n",
    "    else:\n",
    "        level=level+1\n",
    "        recursiveParent(nameP,level)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a9fb1f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "recursiveParent(\"AR0019.1.0101\",1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1801af74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
