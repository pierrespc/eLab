{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "addba8b7",
   "metadata": {},
   "source": [
    "# A notebook to read a CSV template with Site/Individual/Skeleton Element info and load it to elab\n",
    "\n",
    "Please enter file name in the following cell, and what is the delimiter in that file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57d76698",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSVfilename=\"/Users/pierrespc/Documents/PostDocPasteur/aDNA/LumilaMenendez/2022-03-21-ListScannedForEleb.txt\"\n",
    "delimiterFile=\"\\t\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2742e51",
   "metadata": {},
   "source": [
    "Please enter the one-line file where your token is saved in the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67cdcb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenFile=\"/Users/pierrespc/Documents/PostDocPasteur/aDNA/Import_eLAB/API_FUNCTIONALITIES/credentials/tokenELAB\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fa9f66",
   "metadata": {},
   "source": [
    "Now preparing all required python libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3dd8bb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import csv\n",
    "import pandas\n",
    "import numpy\n",
    "from apiclient import discovery, errors\n",
    "from httplib2 import Http\n",
    "from oauth2client import client, file, tools\n",
    "import os.path\n",
    "\n",
    "token = format(open(tokenFile,\"r\").readline().strip())\n",
    "url = \"https://elab-dev.pasteur.fr/api/v1/\"\n",
    "headers1 = {'Authorization': token, 'Accept': 'application/json','Content-Type':'application/json'}\n",
    "headers2 = {'Authorization': token, 'Accept': 'application/json'}\n",
    "params={}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a0e6d6",
   "metadata": {},
   "source": [
    "Reading the data. SkelDict is to make sure thta if eLab configuration change we just need to change here and not the excel template. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3f64033",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skeleton Element</th>\n",
       "      <th>Skeleton Element_Scanned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AR0049.2</td>\n",
       "      <td>SCANNED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AR0054.2</td>\n",
       "      <td>SCANNED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AR0378.1</td>\n",
       "      <td>SCANNED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AR0379.1</td>\n",
       "      <td>SCANNED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AR0380.1</td>\n",
       "      <td>SCANNED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>AR0669.1</td>\n",
       "      <td>SCANNED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>AR0697.1</td>\n",
       "      <td>SCANNED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>AR0699.1</td>\n",
       "      <td>SCANNED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>AR0700.1</td>\n",
       "      <td>SCANNED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>AR0701.1</td>\n",
       "      <td>SCANNED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>185 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Skeleton Element Skeleton Element_Scanned\n",
       "0           AR0049.2                  SCANNED\n",
       "1           AR0054.2                  SCANNED\n",
       "2           AR0378.1                  SCANNED\n",
       "3           AR0379.1                  SCANNED\n",
       "4           AR0380.1                  SCANNED\n",
       "..               ...                      ...\n",
       "180         AR0669.1                  SCANNED\n",
       "181         AR0697.1                  SCANNED\n",
       "182         AR0699.1                  SCANNED\n",
       "183         AR0700.1                  SCANNED\n",
       "184         AR0701.1                  SCANNED\n",
       "\n",
       "[185 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "DICT={\"Site\":{\n",
    "        \"Name\":\"Site\",\n",
    "        \"Description\":\"None\",\n",
    "        \"Note\":\"None\",\n",
    "        \"Amount\":\"fixed_1\",\n",
    "        \"Unit\":\"fixed_unit\",\n",
    "        \"Main geographic region\":\"Site_Main Geographic Region\",\n",
    "        \"Country\":\"Site_Country\",\n",
    "        \"Province / Region\":\"Site_Province / Region\",\n",
    "        \"Locality\":\"Site_Locality\",\n",
    "        \"Latitude\":\"Site_LatChanged\",\n",
    "        \"Longitude\":\"Site_LongChanged\",\n",
    "        \"Site type\":\"Site_Site type\",\n",
    "        \"Pictures\":\"None\",\n",
    "        \"parentSampleID\":\"None\"\n",
    "    },\n",
    "\n",
    "    \"Individual\":{\n",
    "        \"Name\":\"Individual\",\n",
    "        #\"Description\":\"Individual_Archaeologist Observations\",\n",
    "        \"Description\":\"None\",\n",
    "        \"Note\":\"None\",\n",
    "        \"Amount\":\"fixed_1\",\n",
    "        #\"Unit\":\"fixed_Unit | pcs\",\n",
    "        \"Unit\":\"fixed_unit\",\n",
    "        \"parentSampleID\":\"Site\",\n",
    "        \"Archaeologist ID\":\"Individual_Archaeologist ID\",\n",
    "        \"Archaeologist group\":\"Individual_Archaeologist group\",\n",
    "        \"Site Name\":\"Site\",\n",
    "        \"Date\":\"Individual_Date\",\n",
    "        \"Datation method\":\"Individual_Datation method\",\n",
    "        \"Subsistence Strategy\": \"Individual_Subsistence Strategy\",\n",
    "        \"Age\":\"Individual_Age\",\n",
    "        \"Gender\":\"Individual_Gender\",\n",
    "        \"Pictures\":\"None\",\n",
    "        \"Linked individuals\":\"None\"\n",
    "    },\n",
    "\n",
    "    \"Skeleton Element\":{\"Name\":\"Skeleton Element\",\n",
    "         \"From Individual\":\"Individual\",\n",
    "         \"Description\":\"Skeleton Element_description\",\n",
    "         \"Note\":\"None\",\n",
    "         \"Amount\":\"fixed_1\",\n",
    "         #\"Unit\":\"fixed_Unit | pcs\",\n",
    "         \"Unit\":\"fixed_unit\",\n",
    "         \"parentSampleID\":\"Individual\",\n",
    "         \"Archaeologist sample ID\":\"Skeleton Element_Archaeologist sample ID\",\n",
    "         \"Pictures Labelling\":\"Skeleton Element_Pictures Labelling\",\n",
    "         \"Pictures Drilling\":\"None\",\n",
    "         \"Bone type\":\"Skeleton Element_Bone type\",\n",
    "         \"Skeleton element\":\"Skeleton Element_Skeleton element\",\n",
    "         \"Exportation Permit Number\":\"Skeleton Element_Exportation Permit Number\",\n",
    "         \"Observation Labelling\":\"Skeleton Element_Observation Labelling\",\n",
    "         \"Observation Scanning\":\"Skeleton Element_Observation Scanning\",\n",
    "         \"Observation Drilling\":\"None\",\n",
    "         \"Scanned\":\"Skeleton Element_Scanned\"\n",
    "\n",
    "         \n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Table=pandas.read_csv(CSVfilename,delimiter=delimiterFile)\n",
    "\n",
    "Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2f6ea8",
   "metadata": {},
   "source": [
    "We remove all columns that only have null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "485b5a52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skeleton Element</th>\n",
       "      <th>Skeleton Element_Scanned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AR0049.2</td>\n",
       "      <td>SCANNED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AR0054.2</td>\n",
       "      <td>SCANNED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AR0378.1</td>\n",
       "      <td>SCANNED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AR0379.1</td>\n",
       "      <td>SCANNED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AR0380.1</td>\n",
       "      <td>SCANNED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>AR0669.1</td>\n",
       "      <td>SCANNED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>AR0697.1</td>\n",
       "      <td>SCANNED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>AR0699.1</td>\n",
       "      <td>SCANNED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>AR0700.1</td>\n",
       "      <td>SCANNED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>AR0701.1</td>\n",
       "      <td>SCANNED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>185 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Skeleton Element Skeleton Element_Scanned\n",
       "0           AR0049.2                  SCANNED\n",
       "1           AR0054.2                  SCANNED\n",
       "2           AR0378.1                  SCANNED\n",
       "3           AR0379.1                  SCANNED\n",
       "4           AR0380.1                  SCANNED\n",
       "..               ...                      ...\n",
       "180         AR0669.1                  SCANNED\n",
       "181         AR0697.1                  SCANNED\n",
       "182         AR0699.1                  SCANNED\n",
       "183         AR0700.1                  SCANNED\n",
       "184         AR0701.1                  SCANNED\n",
       "\n",
       "[185 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colDrop=[]\n",
    "for col in Table.keys():\n",
    "    if Table[col].isnull().all():\n",
    "        print(col+\" only empty values--> we remove\")\n",
    "        colDrop.append(col)\n",
    "print(colDrop)\n",
    "Table=Table.drop(labels=colDrop,axis=1)\n",
    "Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee66e0f",
   "metadata": {},
   "source": [
    "Make \"Skeleton Element_Bone type\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7960971f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Skeleton Element Skeleton Element_Scanned\n",
      "0           AR0049.2                  SCANNED\n",
      "1           AR0054.2                  SCANNED\n",
      "2           AR0378.1                  SCANNED\n",
      "3           AR0379.1                  SCANNED\n",
      "4           AR0380.1                  SCANNED\n",
      "..               ...                      ...\n",
      "180         AR0669.1                  SCANNED\n",
      "181         AR0697.1                  SCANNED\n",
      "182         AR0699.1                  SCANNED\n",
      "183         AR0700.1                  SCANNED\n",
      "184         AR0701.1                  SCANNED\n",
      "\n",
      "[185 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(Table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95998071",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Skeleton Element_Skeleton element'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3080\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3081\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3082\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Skeleton Element_Skeleton element'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-c36912b741d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m \u001b[0mTable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDICT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Skeleton Element'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Bone type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDICT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Skeleton Element'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Skeleton element'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefineBoneTypefunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0mTable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDICT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Skeleton Element'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Bone type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3022\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3024\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3025\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3081\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3082\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3083\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3085\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Skeleton Element_Skeleton element'"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "def defineBoneTypefunction(ele):\n",
    "    l1=list(range(1,9)) * 8\n",
    "    l2=list(itertools.chain.from_iterable(itertools.repeat(x, 8) for x in list(range(1,9))))\n",
    "    l3=[]\n",
    "    for i in list(range(0,len(l1))):\n",
    "        l3.append(str(l1[i])+\".\"+str(l2[i]))\n",
    "\n",
    "\n",
    "    toothElements=[\"tooth\",\n",
    "               \"diente\",\n",
    "               \"molar\",\n",
    "               \"mx\",\n",
    "               \"42 inf. 1° derecho\",\n",
    "               \" m \",\n",
    "               \" md\",\n",
    "               \"incisive\",\n",
    "               \"incisivo\",\n",
    "               \"incisor\",\n",
    "               \"canino\",\n",
    "               \"canine\",\n",
    "               l3,\n",
    "               \"1.1 o 2.1\",\n",
    "               \"1.5 o 2.5\",\n",
    "                \"1mid\",\n",
    "                \"1mii\",\n",
    "                \"1pmid\",\n",
    "                \"1pmii\",\n",
    "                \"2iid\",\n",
    "                \"2iii\",\n",
    "                \"2isi\",\n",
    "                \"2mid\",\n",
    "                \"2mii\",\n",
    "                \"2pmid\",\n",
    "                \"2pmii\",\n",
    "                \"2pmsd\",\n",
    "                \"2pmsi\",\n",
    "                \"2isd\",\n",
    "                \"2isi\",\n",
    "                \"2minf.\",\n",
    "                \"3mid\",\n",
    "                \"3mii\",\n",
    "                \"3minf.\"]\n",
    "    \n",
    "    calculusElements=[\"calculus\",\n",
    "                      \"from 1isd\",\n",
    "                      \"from 1isi\",\n",
    "                      \"from 1pmii\",\n",
    "                      \"from 2iii\",\n",
    "                      \"from 2pmii\",\n",
    "                      \"from 3mii\",\n",
    "                      \"from cid\"]\n",
    "\n",
    "    petrousElements=[\"petrous\",\n",
    "                 \"petroso\",\n",
    "                 \"petrozo\"]\n",
    "\n",
    "    undefinedElements=[\"??\"]\n",
    "    otherElements=[\"rib\",\n",
    "               \"fibula\",\n",
    "               \"matoideo\",\n",
    "               \"metatarsal\",\n",
    "               \"humer\",\n",
    "               \"humerus\",\n",
    "               \"lumbar\",\n",
    "               \"craneo\",\n",
    "               \"vertebra\",\n",
    "               \"tibia\",\n",
    "               \"radio\",\n",
    "               \"phalanx\",\n",
    "               \"phalange\",\n",
    "               \"longbone\",\n",
    "               \"femur\",\n",
    "               \"metacarpo\",\n",
    "               \"metatarsus\",\n",
    "               \"tarseano\",\n",
    "               \"hueso\",\n",
    "               \"femur\",\n",
    "                \"calota\",\n",
    "              \"tarso\"]\n",
    "\n",
    "    noHumanElements=[\"valva\"]    \n",
    "    \n",
    "    lowerEle=ele.lower()\n",
    "    if bool([ttt for ttt in toothElements if(lowerEle in ttt or str(ttt) in lowerEle)]):\n",
    "        return(\"Tooth\")        \n",
    "    elif bool([ttt for ttt in calculusElements if(lowerEle in ttt or str(ttt) in lowerEle)]):\n",
    "        return(\"Dental Calculus\")\n",
    "    elif bool([ttt for ttt in petrousElements if(lowerEle in ttt or str(ttt) in lowerEle)]):\n",
    "        return(\"Petrous\")\n",
    "    elif bool([ttt for ttt in otherElements if(lowerEle in ttt or str(ttt) in lowerEle)]):\n",
    "        return(\"Other Bone\")\n",
    "    elif bool([ttt for ttt in undefinedElements if(lowerEle in ttt or str(ttt) in lowerEle)]):\n",
    "        return(\"Undefined\")\n",
    "    elif bool([ttt for ttt in noHumanElements if(lowerEle in ttt or str(ttt) in lowerEle)]):\n",
    "        return(\"non Human\")\n",
    "    else:\n",
    "        print(ele+\" issue...\")\n",
    "\n",
    "\n",
    "Table[DICT['Skeleton Element']['Bone type']]=Table[DICT['Skeleton Element']['Skeleton element']].apply(defineBoneTypefunction)\n",
    "Table[DICT['Skeleton Element']['Bone type']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208d6585",
   "metadata": {},
   "source": [
    "Format longitud and latitude "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85799845",
   "metadata": {},
   "outputs": [],
   "source": [
    "###change coordinates\n",
    "def changeCOORfunction(coord):\n",
    "    stuf=\"º\"\n",
    "    stuf2=\"°\"\n",
    "    #if coord is None or numpy.isnan(coord):\n",
    "    if coord is None:\n",
    "        #return([None,None,None,None])\n",
    "        return(None)\n",
    "                      \n",
    "    coord=format(coord)\n",
    "    coordFed=coord\n",
    "    #print(coord)\n",
    "    #####HERE CHANGE ALL WEIRD CHARACTERS THAT CAN COME ON THE WAY\n",
    "    coord=coord.replace(\"39° 06 ́\",\"39°06'\")\n",
    "    coord=coord.replace(\"63° 47 ́\",\"63°47'\") \n",
    "    ##change weird degrees characters\n",
    "    coord=coord.replace(stuf2,stuf)\n",
    "    coord=coord.replace(\"d\",stuf)\n",
    "    ##change weird minutes characters\n",
    "    coord=coord.replace(\"``\",\"\\\"\")\n",
    "    coord=coord.replace(\"´´\",\"\\\"\")\n",
    "    coord=coord.replace(\"”\",\"\\\"\")\n",
    "    coord=coord.replace(\"''\",\"\\\"\")\n",
    "    coord=coord.replace(\"’’\",\"\\\"\")\n",
    "    coord=coord.replace(\"“\",\"\\\"\")\n",
    "    ##change weird seconds characters\n",
    "    coord=coord.replace(\" ´\",\"'\")\n",
    "    coord=coord.replace(\"`\",\"'\")\n",
    "    coord=coord.replace(\"´\",\"'\")\n",
    "    coord=coord.replace(\"’\",\"'\")\n",
    "    ###we now that it is all South and West\n",
    "    coord=coord.replace(\" \",\"\")\n",
    "    coord=coord.replace(\"S\",\"\")\n",
    "    coord=coord.replace(\"O\",\"\")\n",
    "    coord=coord.replace(\"W\",\"\")\n",
    "    ###change decimal character\n",
    "    coord=coord.replace(\",\",\".\")\n",
    "\n",
    "    ##read degrees\n",
    "    if len(coord.split(stuf)) ==2 :\n",
    "        if coord.split(stuf)[1] == \"\":\n",
    "            if stuf not in coord:\n",
    "                coord=coord + stuf + \"0'\"\n",
    "            else:\n",
    "                coord=coord+\"0'\"\n",
    "    elif len(coord.split(stuf)) == 1 :\n",
    "        if stuf not in coord:\n",
    "            coord=coord + stuf + \"0'\"\n",
    "        else:\n",
    "            coord=coord+\"0'\"\n",
    "    else:\n",
    "        print(\"splitting minute/second \" + coordFed + \"-->\" + coord)\n",
    "            \n",
    "    deg=coord.split(stuf)[0]\n",
    "    ###read minutes and seconds\n",
    "    tmp=coord.split(stuf)[1]\n",
    "    minute=tmp.split(\"'\")[0]\n",
    "    if len(tmp.split(\"'\")) != 2:\n",
    "        print( coord.split(stuf))\n",
    "        print(\"splitting minute/second \" + coordFed + \"-->\" + coord)\n",
    "        raise()\n",
    "    else:\n",
    "        if tmp.split(\"'\")[1] == \"\":\n",
    "            sec=0\n",
    "        else:\n",
    "            sec=tmp.split(\"'\")[1]\n",
    "            sec=sec.replace(\"\\\"\",\"\")\n",
    "\n",
    "    #print([coordFed,coord,deg,minute,sec])\n",
    "    ####verify all read ok!\n",
    "    if numpy.isnan(float(deg)):\n",
    "        print(\"pb numerical degree\" + coordFed + \"-->\" +coord + \" (\" + deg + \")\")\n",
    "        raise()\n",
    "    if numpy.isnan(float(minute)):\n",
    "        print(minute)\n",
    "        print(\"pb numerical minute\" + coordFed + \"-->\" +coord + \" (\" + minute + \")\")\n",
    "        raise()\n",
    "    if numpy.isnan(float(sec)):\n",
    "        print(sec)\n",
    "        print(\"pb numerical sec\" + coordFed + \"-->\" + coord + \" (\" + sec + \")\")\n",
    "        raise()\n",
    "  \n",
    "    deg=float(deg)\n",
    "    minute=float(minute)\n",
    "    sec=float(sec)\n",
    "    new=deg+minute/60+sec/3600\n",
    "    if(new<0):\n",
    "        return(new)\n",
    "    else:\n",
    "        return(-new)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "09c5a4c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if \"Site_Latitude\" in Table.keys():\n",
    "\n",
    "    Table.loc[Table['Site_Latitude'].isnull(),\"Site_Latitude\"]=None\n",
    "    Table.loc[Table['Site_Longitude'].isnull(),\"Site_Longitud\"]=None\n",
    "    \n",
    "    \n",
    "    Table.loc[Table[\"Site_Latitude\"].apply(format).isin([ \"Undefined\",\"desconocido\",\"nan\",\"NA\"]),\"Site_Latitude\"]=None\n",
    "    Table.loc[Table[\"Site_Longitude\"].apply(format).isin([ \"Undefined\",\"desconocido\",\"nan\",\"NA\"]),\"Site_Longitude\"]=None\n",
    "\n",
    "    #print(rawTab.loc[rawTab['Latitude']==\"\"])\n",
    "    Table['Site_LatChanged']=Table['Site_Latitude'].apply(changeCOORfunction)\n",
    "    Table['Site_LongChanged']=Table['Site_Longitude'].apply(changeCOORfunction)\n",
    "\n",
    "    print(Table[[\"Site_LatChanged\",\"Site_Latitude\",\"Site_LongChanged\",\"Site_Longitude\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6be764d",
   "metadata": {},
   "source": [
    "Prepare all the eLab-API keys necessary to down and upload data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "73a66616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Individual': '39466', 'Site': '39468', 'Skeleton Element': '39469', 'Extract': '39470', 'Indexed Library': '39494', 'Library pool': '39495', 'Non Indexed Library': '39556', 'Bone pellet': '39599'}\n",
      "{'Individual': {'Name': {'ID': 'notMeta'}, 'Description': {'ID': 'notMeta'}, 'Note': {'ID': 'notMeta'}, 'Amount': {'ID': 'notMeta'}, 'Unit': {'ID': 'notMeta'}, 'parentSampleID': {'ID': 'notMeta'}, 'Archaeologist group': {'ID': '244121', 'TYPE': 'CHECKBOX'}, 'Archaeologist ID': {'ID': '244132', 'TYPE': 'TEXT'}, 'Site Name': {'ID': '244133', 'TYPE': 'SAMPLELINK'}, 'Date': {'ID': '244134', 'TYPE': 'TEXT'}, 'Datation method': {'ID': '244135', 'TYPE': 'TEXTAREA'}, 'Age': {'ID': '244136', 'TYPE': 'TEXT'}, 'Gender': {'ID': '244137', 'TYPE': 'COMBO'}, 'Linked individuals': {'ID': '244138', 'TYPE': 'TEXT'}, 'Pictures': {'ID': '244141', 'TYPE': 'FILE'}}, 'Skeleton Element': {'Name': {'ID': 'notMeta'}, 'Description': {'ID': 'notMeta'}, 'Note': {'ID': 'notMeta'}, 'Amount': {'ID': 'notMeta'}, 'Unit': {'ID': 'notMeta'}, 'parentSampleID': {'ID': 'notMeta'}, 'Exportation Permit Number': {'ID': '244154', 'TYPE': 'TEXT'}, 'From Individual': {'ID': '244155', 'TYPE': 'SAMPLELINK'}, 'Bone type': {'ID': '244158', 'TYPE': 'COMBO'}, 'Skeleton element': {'ID': '244159', 'TYPE': 'TEXT'}, 'Archaeologist sample ID': {'ID': '244160', 'TYPE': 'TEXT'}, 'Observation Drilling': {'ID': '244161', 'TYPE': 'TEXT'}, 'Pictures Labelling': {'ID': '244163', 'TYPE': 'TEXT'}, 'Observation Labelling': {'ID': '244329', 'TYPE': 'TEXT'}, 'Pictures Drilling': {'ID': '245193', 'TYPE': 'TEXT'}, 'Scanned': {'ID': '245781', 'TYPE': 'COMBO'}, 'Observation Scanning': {'ID': '245821', 'TYPE': 'TEXT'}}, 'Site': {'Name': {'ID': 'notMeta'}, 'Description': {'ID': 'notMeta'}, 'Note': {'ID': 'notMeta'}, 'Amount': {'ID': 'notMeta'}, 'Unit': {'ID': 'notMeta'}, 'parentSampleID': {'ID': 'notMeta'}, 'Pictures': {'ID': '244142', 'TYPE': 'FILE'}, 'Main geographic region': {'ID': '244143', 'TYPE': 'CHECKBOX'}, 'Country': {'ID': '244144', 'TYPE': 'COMBO'}, 'Province / Region': {'ID': '244145', 'TYPE': 'COMBO'}, 'Locality': {'ID': '244146', 'TYPE': 'TEXT'}, 'Latitude': {'ID': '244147', 'TYPE': 'NUMERIC'}, 'Longitude': {'ID': '244148', 'TYPE': 'NUMERIC'}, 'Site type': {'ID': '244150', 'TYPE': 'TEXT'}}}\n"
     ]
    }
   ],
   "source": [
    "def BadRequest(myReq,code=200):\n",
    "    return(myReq.status_code !=code)\n",
    "\n",
    "\n",
    "r = requests.get(url + \"sampleTypes\", headers = headers2)\n",
    "if BadRequest(r,200):\n",
    "    r.raise_for_status()\n",
    "data = r.json()\n",
    "types = {}\n",
    "for typ in data.get(\"data\"):\n",
    "    types[format(typ.get(\"name\"))] = format(typ.get(\"sampleTypeID\"))\n",
    "\n",
    "print(types)\n",
    "\n",
    "\n",
    "FeateLab={}\n",
    "for sampTY in [\"Individual\",\"Skeleton Element\",\"Site\"]:\n",
    "    r = requests.get(url + \"sampleTypes/\" + types[sampTY] + \"/meta\", headers = headers2)\n",
    "    if BadRequest(r,200):\n",
    "        r.raise_for_status()\n",
    "    data = r.json()\n",
    "    FeateLab[sampTY] = {}\n",
    "    for feat in ['Name','Description','Note','Amount','Unit',\"parentSampleID\"]:\n",
    "        FeateLab[sampTY][feat] = {\"ID\": \"notMeta\"}\n",
    "    for feat in data.get(\"data\"):\n",
    "        FeateLab[sampTY][format(feat.get(\"key\"))] = { \"ID\":format(feat.get(\"sampleTypeMetaID\")),\n",
    "                                              \"TYPE\":format(feat.get(\"sampleDataType\"))}\n",
    "\n",
    "print(FeateLab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bdf485",
   "metadata": {},
   "source": [
    "Check the columns in  Table are recognized here. If no lines in output, you are just fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a091617",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sampTY in  FeateLab.keys():\n",
    "    for feat in FeateLab[sampTY].keys():\n",
    "        if feat not in DICT[sampTY].keys():\n",
    "            exit(sampTY+\": \"+feat + \"--> NOT IN DICTIONARY\")\n",
    "        \n",
    "    for feat in DICT[sampTY].keys():\n",
    "        if feat not in FeateLab[sampTY].keys():\n",
    "            exit(sampTY+\": \"+feat + \"--> NOT IN eLAB\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0342d6c",
   "metadata": {},
   "source": [
    "We get all the possible values for checkboxes and dropdown features of Extracts and check our extractTable table is fine. If no lines in output, you're just fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "49b79ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sampTY in FeateLab.keys():\n",
    "    r = requests.get(url + \"sampleTypes/\" + types[sampTY] + \"/meta\", headers = headers2)\n",
    "    data = r.json()\n",
    "    for feat in data.get(\"data\"):\n",
    "        key=feat.get(\"key\")\n",
    "        if key not in DICT[sampTY].values():\n",
    "            continue\n",
    "        if feat.get(\"sampleDataType\") == \"CHECKBOX\" or feat.get(\"sampleDataType\") == \"COMBO\":\n",
    "            OptionELAB=feat.get(\"optionValues\")\n",
    "            if DICT[sampTY][key].startswith(\"fixed\"):\n",
    "                tabVal=DICT[sampTY][key].split(\"_\")[1]\n",
    "                if tabVal not in OptionELAB:\n",
    "                    exit(sampTY+\": \" + tabVal + \"-- not mapped in eLab for \" + key)\n",
    "            else:\n",
    "                Table.loc[Table[DICT[sampTY][key]].isnull(),DICT[sampTY][key]]=\"NA\"\n",
    "                for tabVal in Table[DICT[sampTY][key]].unique():\n",
    "                    if tabVal not in OptionELAB:\n",
    "                        exit(sampTY+\": \" + tabVal + \"-- not mapped in eLab for \" + key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0730634",
   "metadata": {},
   "source": [
    "Now, we make the json for each extract and we upload or update in eLab!\n",
    "Change the default prompt line:\n",
    "- put y if you are sure you want to overwrite already loaded info in eLab, \n",
    "- put n if you are sure you want to leave already loaded info in eLab (although it doesn't match info in your table)\n",
    "- put anything else if you want a case by case prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b3b8c93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "####get all registered skeleton element and extracts\n",
    "registered = {}\n",
    "for name in [\"Skeleton Element\",\"Individual\",\"Site\"]:\n",
    "    #print(name)\n",
    "    r = requests.get(url + \"samples\" , headers = headers2, params = {'sampleTypeID': types[name]})\n",
    "    if BadRequest(r,200):\n",
    "        r.raise_for_status()\n",
    "    data = r.json()\n",
    "    myList = {}\n",
    "    for sam in data.get(\"data\"):\n",
    "        if format(sam.get(\"name\")) in myList.keys():\n",
    "            print(name + \": \" + sam.get(\"name\") + \" duplicated\")\n",
    "            break\n",
    "        myList[format(sam.get(\"name\"))]=format(sam.get(\"sampleID\"))\n",
    "    registered[name] = myList\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3761b15a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AR0049.2\n",
      "For Skeleton Element AR0049.2, do you want to update the Description field? That is: NA vs what already loaded: nan\n",
      "replace y/n??n\n",
      "For Skeleton Element AR0049.2, do you want to update the Note field? That is: NA vs what already loaded: Updated from API\n",
      "no update for None features\n",
      "For Skeleton Element AR0049.2, do you want to update the parentSampleID field? That is: 0 vs what already loaded: 9477567\n",
      "replace y/n??n\n",
      "difference for AR0049.2(feature: Exportation Permit Number) 9477567 vs loaded : /pasteur/entites/metapaleo/Research/ERC-project/Samples/ExportPermits/MonicaBeron/EX-2021-19339322\n",
      "???replace y/n??n\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Individual'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3080\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3081\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3082\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Individual'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-8338d088836c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    130\u001b[0m                               \"sampleDataType\": FeateLab[sampTy][fea]['TYPE']}\n\u001b[1;32m    131\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfea\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"From Individual\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msampTy\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;34m\"Skeleton Element\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfea\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Site Name\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msampTy\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;34m\"Individual\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                     \u001b[0msisi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTableTYPE\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDICT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msampTy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfea\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m                     \u001b[0mIDsisi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregistered\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDICT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msampTy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfea\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msisi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                     \u001b[0melement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msisi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"|\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mIDsisi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3022\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3024\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3025\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3081\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3082\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3083\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3085\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Individual'"
     ]
    }
   ],
   "source": [
    "defaultPrompt=\"?\"\n",
    "\n",
    "#for sampTy in [\"Site\",\"Individual\",\"Skeleton Element\"]:\n",
    "for sampTy in [\"Skeleton Element\"]:\n",
    "    \n",
    "    ###make an unique TableTYPE\n",
    "    TableTYPE={}\n",
    "    for fea in DICT[sampTy].values():\n",
    "        if fea != \"None\" and not fea.startswith(\"fixed\") and fea in Table.keys():\n",
    "            TableTYPE[fea]=Table[fea]\n",
    "        \n",
    "    TableTYPE=pandas.DataFrame(TableTYPE).drop_duplicates()\n",
    "    \n",
    "    ###iterate over extracts in table\n",
    "    for index,name in TableTYPE[DICT[sampTy]['Name']].items():\n",
    "        print(name)\n",
    "        if format(name)==\"nan\":\n",
    "            continue\n",
    "        patch=False\n",
    "        ###get what is already uploaded for that extract in eLab\n",
    "        if name in registered[sampTy].keys():\n",
    "            patch=True\n",
    "            id=registered[sampTy][name]\n",
    "            r=requests.get(url + \"samples/\"+id, headers = headers2)\n",
    "            if BadRequest(r,200):\n",
    "                r.raise_for_status()\n",
    "            r=r.json()\n",
    "        \n",
    "            ###change to lower case all the keys because API sometimes use upper, lower for different request (A MESS!)\n",
    "            dataLoaded={}\n",
    "            for oldkey in r:\n",
    "                newkey=oldkey.lower()\n",
    "                dataLoaded[newkey] = r[oldkey]\n",
    "        ####prepare the Data to be loaded\n",
    "        Data={}\n",
    "        for fea in FeateLab[sampTy].keys():\n",
    "            if FeateLab[sampTy][fea]['ID'] == \"notMeta\" and fea not in [\"Amount\",\"Unit\"]:\n",
    "                ###fixed value (from dico)\n",
    "                if DICT[sampTy][fea].startswith(\"fixed\"):\n",
    "                    element=DICT[sampTy][fea].split(\"_\")[1]\n",
    "                ###WHEN NO VALUE to enter\n",
    "                elif DICT[sampTy][fea]==\"None\" or DICT[sampTy][fea] not in TableTYPE.keys():\n",
    "                    if fea == \"parentSampleID\":\n",
    "                        element=0\n",
    "                    else:\n",
    "                        element=\"NA\"\n",
    "                elif fea == \"parentSampleID\":\n",
    "                    if sampTy == \"Site\":\n",
    "                        continue\n",
    "                    element=registered[DICT[sampTy][\"parentSampleID\"]][TableTYPE[DICT[sampTy][\"parentSampleID\"]][index]]\n",
    "                else:\n",
    "                    element=TableTYPE[DICT[sampTy][fea]][index]\n",
    "                ###check delta when patching\n",
    "                if patch:\n",
    "                    elementLoaded=dataLoaded[fea.lower()]\n",
    "                    if format(elementLoaded) != format(element):\n",
    "                        print(\"For \"+sampTy+\" \"+name+\", do you want to update the \"+fea+\" field? That is: \"+format(element)+ \" vs what already loaded: \"+format(elementLoaded))\n",
    "                        if DICT[sampTy][fea]==\"None\":\n",
    "                            print(\"no update for None features\")\n",
    "                            prompt=\"n\"\n",
    "                        else:\n",
    "                            prompt=defaultPrompt\n",
    "                            while prompt not in [\"y\",\"n\"]:\n",
    "                                prompt = input(\"replace y/n??\")\n",
    "                        if prompt == \"n\":\n",
    "                             element=elementLoaded\n",
    "                Data[fea]=element\n",
    "        ###case of updating\n",
    "        if patch:\n",
    "            DR=requests.patch(url + \"samples/\"+id, headers = headers2,data = Data)\n",
    "            if BadRequest(DR,204):\n",
    "                DR.raise_for_status()\n",
    "        else:\n",
    "            ###case of uploading\n",
    "            #print(name + \"uploading\")\n",
    "            patch=False\n",
    "            Data[\"sampleTypeID\"]=types[sampTy]\n",
    "            Data[\"Name\"]=name\n",
    "            DR=requests.post(url + \"samples/\", headers = headers2,data = Data)   \n",
    "\n",
    "        ####check the Data loading was correct\n",
    "        if BadRequest(DR,204):\n",
    "            DR.raise_for_status()\n",
    "            \n",
    "        ###actualize the registered[<sample type>] list (checking we did not duplicated anything here)\n",
    "        r=requests.get(url + \"samples/forNames?names=\"+name, headers = headers2)\n",
    "        if BadRequest(r,200):\n",
    "            r.raise_for_status()\n",
    "        data=r.json()\n",
    "        sam=data.get(\"data\")\n",
    "        if len(sam)!=1:\n",
    "            exit(\"different \"+sampTy+\" entries (\" + str(len(sam)) + \") for name \"+name)    \n",
    "        else:\n",
    "            sam=sam[0]\n",
    "            id=str(sam.get(\"sampleID\"))\n",
    "            #print(\"Data OK for \"+ name + \" (\" + id + \")\")\n",
    "            registered[sampTy][name]=id\n",
    "\n",
    "        ###patch the metaData\n",
    "        \n",
    "        if patch:\n",
    "            #print(\"patching meta so need to check if differences for \"+name)\n",
    "            MDR=requests.get(url + \"samples/\"+id+\"/meta\", headers = headers2)\n",
    "            if BadRequest(MDR,200):\n",
    "                MDR.raise_for_status()\n",
    "            data=MDR.json().get(\"data\")\n",
    "            metaLoaded={}\n",
    "            for i in data:\n",
    "                metaLoaded[i[\"key\"]]=str(i[\"value\"])\n",
    "        for fea in FeateLab[sampTy].keys():\n",
    "\n",
    "            needToPatch=False\n",
    "            #MDR=requests.get(url + \"samples/\"+id+\"/meta\", headers = headers2)\n",
    "            #if BadRequest(MDR,200):\n",
    "            #    MDR.raise_for_status()\n",
    "            ###get new element to be loaded\n",
    "            if FeateLab[sampTy][fea]['ID'] != \"notMeta\" and FeateLab[sampTy][fea]['TYPE'] != \"FILE\":\n",
    "                ###fixed value (from dico)\n",
    "                if DICT[sampTy][fea].startswith(\"fixed\"):\n",
    "                    element=DICT[sampTy][fea].split(\"_\")[1]\n",
    "                    MetaData={\"key\": fea,\n",
    "                              \"sampleTypeMetaID\": int(FeateLab[sampTy][fea]['ID']),\n",
    "                              \"value\": element,\n",
    "                              \"sampleDataType\": FeateLab[sampTy][fea]['TYPE']}\n",
    "                elif DICT[sampTy][fea]==\"None\":\n",
    "                    element=\"NA\"\n",
    "                    MetaData={\"key\": fea,\n",
    "                              \"sampleTypeMetaID\": int(FeateLab[sampTy][fea]['ID']),\n",
    "                              \"value\": element,\n",
    "                              \"sampleDataType\": FeateLab[sampTy][fea]['TYPE']}\n",
    "                elif (fea == \"From Individual\" and sampTy ==\"Skeleton Element\") or (fea == \"Site Name\" and sampTy ==\"Individual\"):\n",
    "                    sisi=TableTYPE[DICT[sampTy][fea]][index]\n",
    "                    IDsisi=registered[DICT[sampTy][fea]][sisi]\n",
    "                    element=sisi+\"|\"+IDsisi\n",
    "                    samples={\"sampleID\": IDsisi,\"name\": sisi}\n",
    "                \n",
    "                    MetaData={\n",
    "                        \"sampleTypeMetaID\": int(FeateLab[sampTy][fea]['ID']),\n",
    "                        \"sampleDataType\": FeateLab[sampTy][fea]['TYPE'],\n",
    "                        \"samples\": samples,\n",
    "                        \"key\": fea,\n",
    "                        \"value\": element\n",
    "                    }\n",
    "                elif DICT[sampTy][fea] in TableTYPE.keys():\n",
    "                    element=TableTYPE[DICT[sampTy][fea]][index]\n",
    "                    if format(element)==\"nan\" or format(element)==\"\" or format(element)==\" \":\n",
    "                        element=\"NA\"\n",
    "                    MetaData={\"key\": fea,\n",
    "                              \"sampleTypeMetaID\": int(FeateLab[sampTy][fea]['ID']),\n",
    "                              \"value\": element,\n",
    "                              \"sampleDataType\": FeateLab[sampTy][fea]['TYPE']}\n",
    "            \n",
    "                ###check if this is a new entry or not\n",
    "                if patch:\n",
    "                    ###check if new element is similar to what already loaded\n",
    "                    if fea not in metaLoaded.keys(): \n",
    "                        needToPatch=True\n",
    "                    elif metaLoaded[fea] != str(element):\n",
    "                        print(\"difference for \" + name + \"(feature: \" + fea + \") \" + str(element) + \" vs loaded : \" + metaLoaded[fea])\n",
    "                        if DICT[sampTy][fea]==\"None\":\n",
    "                            print(\"no update for None features\")\n",
    "                            prompt=\"n\"\n",
    "                        else:\n",
    "                            prompt=defaultPrompt\n",
    "                            while prompt not in [\"y\",\"n\"]:\n",
    "                                prompt = input(\"???replace y/n??\")\n",
    "                        if prompt == \"y\":\n",
    "                            needToPatch=True\n",
    "                else:\n",
    "                    needToPatch=True\n",
    "                if needToPatch:\n",
    "                    #print(MetaData)      \n",
    "                    MDR=requests.put(url + \"samples/\"+id+\"/meta\", headers = headers2,data = MetaData)\n",
    "                    ####check the MetaData loading was correct\n",
    "                    if BadRequest(MDR,204):\n",
    "                        MDR.raise_for_status()\n",
    "        #print(\"metadata OK for \"+ name + \" (\" + id + \")\")\n",
    "        ###patch the quantity\n",
    "        Quant={}\n",
    "        Note=None\n",
    "        for fea in ['Amount','Unit']:\n",
    "            if DICT[sampTy][fea].startswith(\"fixed\"):\n",
    "                element=DICT[sampTy][fea].split(\"_\")[1]\n",
    "            elif DICT[sampTy][fea]==\"None\":\n",
    "                element=\"NA\"\n",
    "            else:\n",
    "                element=TableTYPE[DICT[sampTy][fea]][index]\n",
    "                if format(element)==\"nan\":\n",
    "                    element=0\n",
    "                elif \"<\" in format(element):\n",
    "                    Note=\"actual amount reported: \"+element\n",
    "                    element=0\n",
    "            Quant[fea]=element\n",
    "        Quant[\"displayUnit\"]=Quant[\"Unit\"].capitalize()\n",
    "        Quant[\"fullAmount\"]=Quant[\"Amount\"]\n",
    "        QR=requests.put(url + \"samples/\" + id + \"/quantity\", headers = headers2, data = Quant)\n",
    "        if BadRequest(QR,204):\n",
    "            QR.raise_for_status()\n",
    "            ###put actual weight in note when there is a \"<\"\n",
    "\n",
    "        if Note is not None:\n",
    "            r=requests.get(url + \"samples/\"+id, headers = headers2)\n",
    "            if BadRequest(r,200):\n",
    "                r.raise_for_status()\n",
    "            Data=r.json()\n",
    "            Data[\"note\"]=Data[\"note\"]+\" / \"+ Note\n",
    "            r=requests.patch(url + \"samples/\"+id, headers = headers2,data = Data)\n",
    "            if BadRequest(r,204):\n",
    "                r.raise_for_status()\n",
    "        \n",
    "    break\n",
    "print(\"finished\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2415d01",
   "metadata": {},
   "source": [
    "## Assignation to storage\n",
    "first organize the storage IDs (a bit messy but eLab treats all storage levels similarly for sample assignation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a122eb7c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "storageByID={}\n",
    "r=requests.get(url+\"/storageLayers\",headers=headers1)\n",
    "if BadRequest(r,200):\n",
    "    r.raise_for_status()\n",
    "    \n",
    "stoData=r.json().get(\"data\")\n",
    "for sto in stoData:\n",
    "    \n",
    "    storageByID[sto[\"storageLayerID\"]]={\"name\":sto[\"name\"],\"parentID\":sto[\"parentStorageLayerID\"]}\n",
    "\n",
    "def getParentSto(ID,stoDict):\n",
    "    if stoDict[ID][\"parentID\"]==0:\n",
    "        return(stoDict[ID][\"name\"])\n",
    "    else:\n",
    "        return(getParentSto(stoDict[ID][\"parentID\"],stoDict)+\", \"+stoDict[ID][\"name\"])\n",
    "    \n",
    "storage={}\n",
    "storageRev={}\n",
    "for stoID in storageByID.keys():\n",
    "    name=getParentSto(stoID,storageByID)\n",
    "    storage[name]=stoID\n",
    "    storageRev[stoID]=name\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35bfc5e",
   "metadata": {},
   "source": [
    "### Individual and Site  assignation to Artefactual Storage \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4b041b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for sampTy in [ \"Skeleton Element\", \"Individual\",\"Site\"]:\n",
    "    TableTYPE={}\n",
    "    for fea in DICT[sampTy].keys():\n",
    "        if DICT[sampTy][fea].startswith(\"Storage\") or fea == \"Name\":\n",
    "            TableTYPE[DICT[sampTy][fea]]=Table[DICT[sampTy][fea]]\n",
    "        \n",
    "    #TableTYPE=TableTYPE.drop_duplicates()\n",
    "    TableTYPE=pandas.DataFrame(TableTYPE).drop_duplicates()\n",
    "    if sampTy+\"_Storage\" not in TableTYPE.keys():\n",
    "        TableTYPE[sampTy+\"_Storage\"]=\"\" \n",
    "    if len(TableTYPE.loc[TableTYPE[sampTy+\"_Storage\"] == \"\",sampTy+\"_Storage\"])>0:\n",
    "        UnspecifiedStorage=\"?\"\n",
    "        while UnspecifiedStorage not in storage:\n",
    "            UnspecifiedStorage=input(\"Storage for \"+sampTy+\" with missing storage info in input table?\")\n",
    "        TableTYPE.loc[TableTYPE[sampTy+\"_Storage\"] ==\"\",sampTy+\"_Storage\"]=UnspecifiedStorage\n",
    "\n",
    "    for index,name in TableTYPE[DICT[sampTy]['Name']].items():\n",
    "        if format(name)==\"nan\":\n",
    "            continue\n",
    "        id=format(registered[sampTy][name])\n",
    "        r=requests.get(url+\"/samples/\"+id,headers=headers1,data={})\n",
    "        if BadRequest(r,200):\n",
    "            r.raise_for_status()\n",
    "        IDstoAlready=r.json()['storageLayerID']\n",
    "        IDsto=storage[ TableTYPE[sampTy+\"_Storage\"][index]]\n",
    "        prompt=defaultPrompt\n",
    "        if IDstoAlready != 0:\n",
    "            if(format(IDstoAlready) != format(IDsto)):\n",
    "                #if storageRev[IDstoAlready] in [\"In Copenhagen\",\"Nico office\",\"In Tartu\",\"Unknown\"]:\n",
    "                #    prompt=\"n\"\n",
    "                #elif storageRev[IDstoAlready] == \"With Lumila\":\n",
    "                #    prompt=\"y\"\n",
    "                while prompt not in [\"y\",\"n\"]:\n",
    "                    prompt=input(\"move \"+name+\" from \"+storageRev[IDstoAlready]+ \" to \"+storageRev[IDsto]+\" (y/n)?\")\n",
    "        else:\n",
    "            prompt=\"y\"\n",
    "        if prompt == \"y\":\n",
    "                r=requests.post(url+\"/samples/moveToLayer/\"+format(IDsto)+\"?sampleIDs=\"+id,headers=headers1,data={})\n",
    "                if BadRequest(r,204):\n",
    "                    r.raise_for_status()\n",
    "print(\"finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c070f28",
   "metadata": {},
   "source": [
    "## Assign individual and Skeleton Element to Labelling experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112dfe19",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(url + \"experiments\", headers = headers2,params = params)\n",
    "data = r.json()\n",
    "experiments = {}\n",
    "for exp in data.get(\"data\"):\n",
    "    experiments[format(exp.get(\"name\"))] = format(exp.get(\"experimentID\"))\n",
    "\n",
    "for expe in [\"Labelling process\"]:\n",
    "    #print(expe)\n",
    "    idExpe=experiments[expe]\n",
    "    r=requests.get(\"https://elab-dev.pasteur.fr/api/v1/experiments/\"+idExpe+\"/sections\",headers=headers1)\n",
    "    if r.status_code != 200:\n",
    "        print(r.status_code)\n",
    "        print(r.raise_for_status())\n",
    "    if r.json().get(\"recordCount\") == 0:\n",
    "        print(\"no record\")\n",
    "        continue\n",
    "    SampleIN={}\n",
    "    SampleOUT={}\n",
    "    for data in r.json().get(\"data\"):\n",
    "        if data[\"sectionType\"] == \"SAMPLESIN\":\n",
    "            SampleIN[data[\"sectionHeader\"]]=data[\"expJournalID\"]\n",
    "        elif data[\"sectionType\"] == \"SAMPLESOUT\":\n",
    "            SampleOUT[data[\"sectionHeader\"]]=data[\"expJournalID\"]\n",
    "    experiments[expe]={\"ID\":idExpe,\n",
    "                      \"sampleIN\":SampleIN,\n",
    "                      \"sampleOUT\":SampleOUT}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sampleOUT=experiments[\"Labelling process\"][\"sampleOUT\"][\"Labelled Skeleton elements \"]\n",
    "sampleIN=experiments[\"Labelling process\"][\"sampleIN\"][\"Individuals labelled\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25223ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "listOUT=[]\n",
    "listIN=[]\n",
    "for i,inName in Table[\"Skeleton Element\"].items():\n",
    "    if(format(inName) == \"nan\"):\n",
    "        continue\n",
    "    inID=registered[\"Skeleton Element\"][inName]\n",
    "    listOUT.append(inID)\n",
    "    ###get the parent individual\n",
    "    r=requests.get(url+\"/samples/\"+inID+\"/parent\",headers=headers1)\n",
    "    if BadRequest(r,200):\n",
    "        r.raise_for_status()\n",
    "        break\n",
    "    rjson=r.json()\n",
    "    outName=rjson.get(\"name\")\n",
    "    listIN.append(rjson.get(\"sampleID\"))\n",
    "\n",
    "print(listIN)\n",
    "print(listOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63ae44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "r=requests.put(url+\"/experiments/sections/\"+format(sampleOUT)+\"/samples\",headers=headers1,data = format(listOUT))\n",
    "if BadRequest(r,204):\n",
    "    r.raise_for_status()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7aacfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "r=requests.put(url+\"/experiments/sections/\"+format(sampleIN)+\"/samples\",headers=headers1,data = format(listIN))\n",
    "if BadRequest(r,204):\n",
    "    r.raise_for_status()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
