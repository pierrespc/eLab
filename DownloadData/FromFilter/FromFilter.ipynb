{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "addba8b7",
   "metadata": {},
   "source": [
    "# A notebook to generate a CSV template with info from samples given a filter, and moving upward and downward\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc50de76",
   "metadata": {},
   "source": [
    "Give the output file name (with path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b4bef05",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=\"/Users/pierrespc/Desktop/2021-12-03_Sites\"\n",
    "f = open(filename, 'w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f759fc5b",
   "metadata": {},
   "source": [
    "## Preparing the note book"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2742e51",
   "metadata": {},
   "source": [
    "Please enter the one-line file where your token is saved in the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67cdcb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenFile=\"/Users/pierrespc/Documents/PostDocPasteur/aDNA/Import_eLAB/API_FUNCTIONALITIES/credentials/tokenELAB\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fa9f66",
   "metadata": {},
   "source": [
    "Now preparing all required python libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dd8bb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import csv\n",
    "import pandas\n",
    "import numpy\n",
    "from apiclient import discovery, errors\n",
    "from httplib2 import Http\n",
    "from oauth2client import client, file, tools\n",
    "import os.path\n",
    "\n",
    "token = format(open(tokenFile,\"r\").readline().strip())\n",
    "url = \"https://elab-dev.pasteur.fr/api/v1/\"\n",
    "headers1 = {'Authorization': token, 'Accept': 'application/json','Content-Type':'application/json'}\n",
    "headers2 = {'Authorization': token, 'Accept': 'application/json'}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6be764d",
   "metadata": {},
   "source": [
    "Prepare all the eLab-API keys necessary to down and upload data. Get list of sample types user is interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73a66616",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def BadRequest(myReq,code=200):\n",
    "    return(myReq.status_code !=code)\n",
    "\n",
    "\n",
    "r = requests.get(url + \"sampleTypes\", headers = headers2)\n",
    "if BadRequest(r,200):\n",
    "    r.raise_for_status()\n",
    "dictType = r.json().get(\"data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4e5027",
   "metadata": {},
   "source": [
    "Now we get all registered ID for all types.\n",
    "(I am lazy now to try to find a clever way to process only the types we need downstream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3c7a1bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual --> 39466\n",
      "Site --> 39468\n",
      "Skeleton Element --> 39469\n",
      "Extract --> 39470\n",
      "Indexed Library --> 39494\n",
      "Library pool --> 39495\n",
      "Non Indexed Library --> 39556\n",
      "Bone pellet --> 39599\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "registered = {}\n",
    "for it in dictType:\n",
    "    name = it.get(\"name\")\n",
    "    ID = it.get(\"sampleTypeID\")\n",
    "    print(name + \" --> \" + format(ID))\n",
    "    r = requests.get(url + \"samples\" , headers = headers2, params = {'sampleTypeID': ID})\n",
    "    if BadRequest:\n",
    "        r.raise_for_status()\n",
    "    data = r.json()\n",
    "    myList = {}\n",
    "    for sam in data.get(\"data\"):\n",
    "        if format(sam.get(\"name\")) in myList.keys():\n",
    "            print(name + \": \" + sam.get(\"name\") + \" duplicated\")\n",
    "            break\n",
    "        myList[format(sam.get(\"name\"))]=format(sam.get(\"sampleID\"))\n",
    "    registered[name] = myList\n",
    "print(\"finished\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b464d912",
   "metadata": {},
   "source": [
    "## Getting which info will be saved in the output table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aab3e52",
   "metadata": {},
   "source": [
    "### Now we get the sample types for which we will output the info and the features we want to retrieve for each sample Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8583620c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interested in getting info from Individual? y/nn\n",
      "interested in getting info from Site? y/ny\n",
      "interested in outputing META feature Pictures? y/ny\n",
      "interested in outputing META feature Main geographic region? y/ny\n",
      "interested in outputing META feature Country? y/ny\n",
      "interested in outputing META feature Province / Region? y/ny\n",
      "interested in outputing META feature Locality? y/ny\n",
      "interested in outputing META feature Latitude? y/ny\n",
      "interested in outputing META feature Longitude? y/ny\n",
      "interested in outputing META feature Site type? y/ny\n",
      "interested in outputing notMETA feature description? y/ny\n",
      "interested in outputing notMETA feature Quantity? y/ny\n",
      "interested in outputing notMETA feature note? y/ny\n",
      "interested in getting info from Skeleton Element? y/nn\n",
      "interested in getting info from Extract? y/nn\n",
      "interested in getting info from Indexed Library? y/nn\n",
      "interested in getting info from Library pool? y/nn\n",
      "interested in getting info from Non Indexed Library? y/nn\n",
      "interested in getting info from Bone pellet? y/nn\n",
      "{'Site': {'key': '39468', 'meta': {'Pictures': 244142, 'Main geographic region': 244143, 'Country': 244144, 'Province / Region': 244145, 'Locality': 244146, 'Latitude': 244147, 'Longitude': 244148, 'Site type': 244150}, 'data': {'description': '', 'Quantity': '', 'note': ''}}}\n"
     ]
    }
   ],
   "source": [
    "types = {}\n",
    "for typ in dictType:\n",
    "    prompt=\"?\"\n",
    "    while prompt not in [\"y\",\"n\"]:\n",
    "        prompt=input(\"interested in getting info from \"+typ.get(\"name\")+\"? y/n\")\n",
    "    if prompt == \"y\":\n",
    "        typName=format(typ.get(\"name\"))\n",
    "        types[typName] = {\"key\":format(typ.get(\"sampleTypeID\")),\n",
    "                                          \"meta\":{},\n",
    "                                          \"data\":{}}\n",
    "        r = requests.get(url + \"sampleTypes/\" + types[typName][\"key\"] + \"/meta\", headers = headers2)\n",
    "        if BadRequest(r,200):\n",
    "            r.raise_for_status()\n",
    "        data = r.json()\n",
    "        for feat in data.get(\"data\"):\n",
    "            if feat.get(\"sampleDataType\") == \"SAMPLELINK\":\n",
    "                continue\n",
    "            prompt=\"?\"\n",
    "            while prompt not in [\"y\",\"n\"]:\n",
    "                prompt=input(\"interested in outputing META feature \"+feat.get(\"key\")+\"? y/n\")\n",
    "            if prompt == \"y\":\n",
    "                types[typName][\"meta\"][feat.get(\"key\")]=feat.get(\"sampleTypeMetaID\")\n",
    "        for feat in [\"description\",\"Quantity\",\"note\"]:\n",
    "            prompt=\"?\"\n",
    "            while prompt not in [\"y\",\"n\"]:\n",
    "                prompt=input(\"interested in outputing notMETA feature \"+feat+\"? y/n\")\n",
    "            if prompt == \"y\":\n",
    "                types[typName][\"data\"][feat]=\"\"\n",
    "print(types)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c6784c",
   "metadata": {},
   "source": [
    "## Defining the filters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d35b97",
   "metadata": {},
   "source": [
    "Some function defintion (just run the following cells without wondering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "798f22df",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def CheckDate(Date):\n",
    "    if Date ==\"?\":\n",
    "        return(False)\n",
    "    else:\n",
    "        tmp=Date.split(\"-\")\n",
    "        tmp=[int(i) for i in tmp]\n",
    "        return(tmp[0] > 2020 and tmp[0] < 2030 and tmp[1] > 0 and tmp[1] < 13 and tmp[2] >0 and tmp[2]<32)\n",
    "\n",
    "def getDateFilter():\n",
    "    wrongEntry=True\n",
    "    while wrongEntry:\n",
    "        MostRecent=\"?\"\n",
    "        while MostRecent != \"9999-12-31\" and not CheckDate(MostRecent):\n",
    "            MostRecent=input(\"Enter the most recent date, i.e. we will filter IN samples before that date (type Any if no filter )\")\n",
    "            if MostRecent == \"Any\":\n",
    "                MostRecent=\"9999-12-31\"\n",
    "        MostRecent=datetime.strptime(MostRecent,'%Y-%m-%d')\n",
    "        Eldest=\"?\"\n",
    "        while Eldest != \"0001-01-01\" and not CheckDate(Eldest):\n",
    "            Eldest=input(\"Enter the eldest date, i.e. i.e. we will filter IN samples after that date (type Any if no filter )\")\n",
    "            if Eldest == \"Any\":\n",
    "                Eldest=\"0001-01-01\"\n",
    "        Eldest=datetime.strptime(Eldest,'%Y-%m-%d')\n",
    "        if Eldest<MostRecent:\n",
    "            wrongEntry=False\n",
    "        else:\n",
    "            print(\"you entered a mostRecent date more ancient and EldestDate\")\n",
    "            \n",
    "    return({\"MostRecent\":MostRecent,\"Eldest\":Eldest})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e2e2635",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOptionFilter(possibleChoices):\n",
    "    print(len(possibleChoices))\n",
    "    wrongEntry=True\n",
    "    while wrongEntry:\n",
    "        print(\"possible choices\")\n",
    "        index=0\n",
    "        for value in possibleChoices:\n",
    "            index=index+1\n",
    "            print(format(index)+\":\"+value)\n",
    "        listEntered=input(\"enter your choice(s) (the number(s) separated by space)\").split()\n",
    "        listEntered=[int(i)-1 for i in listEntered ]\n",
    "        if min(listEntered) <0 or max(listEntered)>=len(possibleChoices):\n",
    "            print(\"you entered choices out of range\")\n",
    "        else:\n",
    "            wrongEntry=False\n",
    "    return([possibleChoices[i] for i in listEntered])\n",
    "\n",
    "\n",
    "###for now we cover just the case where a given string is in the feature (no filter for NOT, OR, AND, NOT ANY, etc...)\n",
    "def getTextFilter():\n",
    "    return(input(\"enter a string to find in the field\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "490cf8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def getLinkFilter(sampleType,allIDs,link):\n",
    "    parentPattern={\"Site\":{\"pattern\":\"Any\",\"typeParent\":\"None\"},\n",
    "                   \"Individual\":{\"pattern\":'[A][R][0-9][0-9][0-9][0-9]',\"typeParent\":\"Site\"},\n",
    "                   \"Skeleton Element\":{\"pattern\":'[A][R][0-9][0-9][0-9][0-9][.][0-9]',\"typeParent\":\"Individual\"},\n",
    "                   \"Extract\":{\"pattern\":'[A][R][0-9][0-9][0-9][0-9][.][0-9][.][0-9]',\"typeParent\":\"Skeleton Element\"}}\n",
    "\n",
    "    if sampleType not in parentPattern.keys():\n",
    "        raise(sampleType+\" not covered to retrieve its parent sample\")\n",
    "    if link:\n",
    "        typeToCheck=parentPattern[sampleType][typeParent]\n",
    "    else:\n",
    "        typeToCheck=sampleType\n",
    "                   \n",
    "    listType=\"?\"\n",
    "    while not listType in [\"prompt\",\"file\"]:        \n",
    "        listType=input(\"will you enter IDs one by one or a file (prompt/file)?\")\n",
    "    wrongEntry=True\n",
    "    while wrongEntry:\n",
    "        if listType==\"file\":\n",
    "            listIDfile=open(input(\"file with parent file\"),\"r\").readlines()\n",
    "            listID=[]\n",
    "            for i in listIDfile:\n",
    "                listID.append(i.strip())\n",
    "        else:\n",
    "            listID=input(\"enter the parent sample IDs separated by <space>/<space>, must match pattern \"+parentPattern[typeToCheck][\"pattern\"])\n",
    "            listID=listID.split(\" / \")\n",
    "        wrongEntry=False\n",
    "        for id in listID:\n",
    "            ###check all id match pattern\n",
    "            if not (re.match(parentPattern[typeToCheck][\"pattern\"],id) or parentPattern[typeToCheck][\"pattern\"] == \"Any\"):\n",
    "                print(\"wrong pattern for \"+id+\" expected: \"+parentPattern[typeToCheck][\"pattern\"])\n",
    "                wrongEntry=True\n",
    "                ###check all id already registered\n",
    "            if not id in allIDs.keys():\n",
    "                print(id+\" not registered in eLab\")\n",
    "                wrongEntry=True\n",
    "        if wrongEntry:\n",
    "            print(\"change those ids either in the file or in the prompted list\")\n",
    "     \n",
    "    bound=\"?\"\n",
    "    while bound not in [\"notin\",\"in\"]:\n",
    "        bound=input(\"keep or remove those IDS (in/notin)?\")\n",
    "    return({\"rule\":bound,\"list\":listID})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2f64b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getQuantityFilter():\n",
    "    wrongEntry=True\n",
    "    while wrongEntry:\n",
    "        quanti=float(input(\"enter a quantity\"))\n",
    "        bound=input(\"enter a bound (less, more, exact)\")\n",
    "        if bound in [\"less\",\"more\",\"exact\"]:\n",
    "            wrongEntry=False\n",
    "    return({\"rule\":bound,\"quantity\":quanti})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d266bd84",
   "metadata": {},
   "source": [
    "### On which field and Sample type you want to filter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f286f3d1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual 5\n",
      "Do you want to apply a filter for Individual?n\n",
      "Site 6\n",
      "Do you want to apply a filter for Site?y\n",
      "for Site, is there a filter for Pictures?n\n",
      "for Site, is there a filter for Main geographic region?n\n",
      "for Site, is there a filter for Country?y\n",
      "2\n",
      "possible choices\n",
      "1:Chile\n",
      "2:Argentina\n",
      "enter your choice(s) (the number(s) separated by space)1 2\n",
      "for Site, is there a filter for Province / Region?n\n",
      "for Site, is there a filter for Locality?n\n",
      "for Site, is there a filter for Latitude?n\n",
      "for Site, is there a filter for Longitude?n\n",
      "for Site, is there a filter for Site type?n\n",
      "for Site, is there a filter for description?n\n",
      "for Site, is there a filter for Quantity?n\n",
      "for Site, is there a filter for note?n\n",
      "for Site, is there a filter for name?n\n",
      "Skeleton Element 4\n",
      "Do you want to apply a filter for Skeleton Element?n\n",
      "Extract 3\n",
      "Do you want to apply a filter for Extract?n\n",
      "Indexed Library 1\n",
      "Do you want to apply a filter for Indexed Library?n\n",
      "Library pool 0\n",
      "Do you want to apply a filter for Library pool?n\n",
      "Non Indexed Library 2\n",
      "Do you want to apply a filter for Non Indexed Library?n\n"
     ]
    }
   ],
   "source": [
    "listFilter={}\n",
    "levelSeq=['Library pool', 'Indexed Library', 'Non Indexed Library', 'Extract','Skeleton Element', 'Individual', 'Site']\n",
    "for typ in dictType:\n",
    "    typName=typ.get(\"name\")\n",
    "    if typName == \"Bone pellet\":\n",
    "        continue\n",
    "    typID=typ.get(\"sampleTypeID\")\n",
    "    level=levelSeq.index(typName)\n",
    "    print(typName+\" \" +format(level))\n",
    "    typeFilter=\"?\"\n",
    "    while typeFilter not in [\"y\",\"n\"]:\n",
    "        typeFilter=input(\"Do you want to apply a filter for \"+typName+\"?\")\n",
    "    if typeFilter == \"y\":\n",
    "        listFilter[typName]={}\n",
    "        r = requests.get(url + \"sampleTypes/\" + format(typID) + \"/meta\", headers = headers2)\n",
    "        if BadRequest(r,200):\n",
    "            r.raise_for_status()\n",
    "        data = r.json()\n",
    "        for meta in data.get(\"data\"):\n",
    "            typeFilter=\"?\"\n",
    "            while typeFilter not in [\"y\",\"n\"]:\n",
    "                typeFilter=input(\"for \"+ typName+\", is there a filter for \"+meta.get(\"key\")+\"?\")\n",
    "                if typeFilter == \"y\":\n",
    "                    listFilter[typName][meta.get(\"key\")]={}\n",
    "                    r = requests.get(url + \"sampleTypes/\" + format(typID) + \"/meta/\"+format(meta.get(\"sampleTypeMetaID\")), headers = headers2)\n",
    "                    if BadRequest(r,200):\n",
    "                        r.raise_for_status()\n",
    "                        \n",
    "                    listFilter[typName][meta.get(\"key\")][\"type\"]=r.json().get(\"sampleDataType\")\n",
    "\n",
    "                    if r.json().get(\"sampleDataType\") == \"DATE\":\n",
    "                        listFilter[typName][meta.get(\"key\")][\"filter\"]=getDateFilter()                           \n",
    "                    elif r.json().get(\"sampleDataType\") == \"CHECKBOX\":\n",
    "                        listFilter[typName][meta.get(\"key\")][\"filter\"]=getOptionFilter(r.json().get(\"optionValues\"))\n",
    "                    elif r.json().get(\"sampleDataType\") == \"COMBO\":\n",
    "                        listFilter[typName][meta.get(\"key\")][\"filter\"]=getOptionFilter(r.json().get(\"optionValues\"))\n",
    "                    elif r.json().get(\"sampleDataType\") == \"TEXT\":\n",
    "                        listFilter[typName][meta.get(\"key\")][\"filter\"]=getTextFilter()\n",
    "                    elif r.json().get(\"sampleDataType\") == \"SAMPLELINK\":\n",
    "                        parentType=levelSeq[level+1]\n",
    "                        listFilter[typName][meta.get(\"key\")][\"filter\"]=getLinkFilter(typName,registered[parentType],True)\n",
    "                    else:\n",
    "                        print(r.json().get(\"sampleDataType\")+\" not covered\")\n",
    "                        break\n",
    "        \n",
    "        for feat in [\"description\",\"Quantity\",\"note\",\"name\"]:\n",
    "            typeFilter=\"?\"\n",
    "            while typeFilter not in [\"y\",\"n\"]:\n",
    "                typeFilter=input(\"for \"+ typName+\", is there a filter for \"+feat+\"?\")\n",
    "            if typeFilter == \"y\":\n",
    "                listFilter[typName][feat]={}\n",
    "                if feat in [\"Observation\",\"Note\"]:\n",
    "                    listFilter[typName][feat][\"type\"]=\"TEXT\"\n",
    "                    listFilter[typName][feat][\"filter\"]=getTextFilter()\n",
    "                elif feat == \"Quantity\":\n",
    "                    listFilter[typName][feat][\"type\"]=\"QUANTITY\"\n",
    "                    listFilter[typName][feat][\"filter\"]=getQuantityFilter()\n",
    "                else:\n",
    "                    listFilter[typName][feat][\"type\"]=\"NAME\"\n",
    "                    listFilter[typName][feat][\"filter\"]=getLinkFilter(typName,registered[typName],False)\n",
    "        if len(listFilter[typName])==0:\n",
    "            print(\"you finally decided not to filter for anything for \"+typName)\n",
    "            del(listFilter[typName])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8541aa",
   "metadata": {},
   "source": [
    "## Let's parse the database, filter the entry and output "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de368600",
   "metadata": {},
   "source": [
    "Following cell is just some function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e23dbd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def filterText(value,filter):\n",
    "    return(filter in value)\n",
    "\n",
    "def filterQuantity(value,thres,ruler):\n",
    "    if ruler == \"exact\":\n",
    "        return(value==thres)\n",
    "    elif ruler == \"less\":\n",
    "        return(value<=thres)\n",
    "    elif ruler == \"more\":\n",
    "        return(value>=thres)\n",
    "    else:\n",
    "        raise(ruler+ \" not recognized\")\n",
    "\n",
    "def filterDate(value,filter):\n",
    "    value=datetime.strptime(value,'%Y-%m-%d')\n",
    "    return(value<=filter[\"MostRecent\"] and value>=filter[\"Eldest\"])\n",
    "\n",
    "def filterLink(value,listNAM,ruler):\n",
    "    value=value.split(\"|\")[0]\n",
    "    if ruler==\"in\":\n",
    "        return(value in listNAM)\n",
    "    elif ruler==\"notin\":\n",
    "        return(value not in listNAM)\n",
    "    else:\n",
    "        raise()\n",
    "\n",
    "        \n",
    "def filterName(value,listNAM,ruler):\n",
    "    if ruler==\"in\":\n",
    "        return(value in listNAM)\n",
    "    elif ruler==\"notin\":\n",
    "        return(value not in listNAM)\n",
    "    else:\n",
    "        raise()\n",
    "    \n",
    "\n",
    "def filterCombo(value,filter):\n",
    "    return(value in filter)\n",
    "\n",
    "def filterCheckbox(value,filter):\n",
    "    AllFound=True\n",
    "    for i in value:\n",
    "        if i not in filter:\n",
    "            AllFound=False\n",
    "    return(AllFound)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29fce5f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Library pool skipped\n",
      "Indexed Library skipped\n",
      "Non Indexed Library skipped\n",
      "Extract skipped\n",
      "Skeleton Element skipped\n",
      "Individual skipped\n",
      "parsing Site\n",
      "we have 164 remaining\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "arrays must all be same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-9a2fee7ac343>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlevel\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"Site\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mlistNextStepKept\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilteredEntries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevelSeq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevelNum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0mfilteredEntries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"df\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilteredEntries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[0;34m(data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         ]\n\u001b[0;32m--> 287\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype, verify_integrity)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mextract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"arrays must all be same length\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: arrays must all be same length"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "startRecord=False\n",
    "filteredEntries={}\n",
    "\n",
    "levelNum=0\n",
    "listNextStepKept=\"FIRSTlevelParsed\"\n",
    "## first we get all entries that match filter for each type\n",
    "for level in levelSeq:\n",
    "    levelNum=levelNum+1\n",
    "    ###check if needed to record entries for that level\n",
    "    if level not in listFilter.keys() and level not in types.keys() and not startRecord:\n",
    "        print(level+\" skipped\")\n",
    "        continue\n",
    "    else:\n",
    "        startRecord=True\n",
    "        filteredEntries[level]={level:[]}\n",
    "        if level!=levelSeq[len(levelSeq)-1]:          \n",
    "            filteredEntries[level][levelSeq[levelNum]]=[]\n",
    "            #filteredEntries[level][\"parent\"]=[]\n",
    "        if level in types.keys():\n",
    "            for entry in types[level][\"meta\"]:\n",
    "                filteredEntries[level][level+\"_\"+entry]=[]\n",
    "            for entry in types[level][\"data\"]:\n",
    "                filteredEntries[level][level+\"_\"+entry]=[]\n",
    "        print(\"parsing \"+ level)\n",
    "        #for sample,idSam in prout.items():\n",
    "        for sample,idSam in registered[level].items():\n",
    "            if listNextStepKept==\"FIRSTlevelParsed\":\n",
    "                filterIN=True\n",
    "            else:\n",
    "                filterIN=filterName(sample,\n",
    "                                    listNextStepKept,\n",
    "                                    \"in\")\n",
    "            if not filterIN:\n",
    "                continue\n",
    "            ##if no filter for that we keep the entry by default\n",
    "            if level in listFilter.keys():\n",
    "                r=requests.get(url+\"/samples/get?sampleID=\"+idSam,headers=headers2)\n",
    "                if BadRequest(r,200):\n",
    "                    r.raise_for_status()\n",
    "                ###filtering for observation and note (not meta data)\n",
    "                if \"name\" in listFilter[level].keys():\n",
    "                    new=filterName(sample,\n",
    "                                   listFilter[level][\"name\"][\"filter\"][\"list\"],\n",
    "                                   listFilter[level][\"name\"][\"filter\"][\"rule\"])\n",
    "                    filterIN=filterIN and new\n",
    "                if \"description\" in listFilter[level].keys() or \"note\" in listFilter[level].keys():\n",
    "                    for filterTy in [\"description\",\"note\"]:\n",
    "                        if filterTy in listFilter[level].keys():\n",
    "                            print(filterTy+\" \"+format(new))\n",
    "                            new=filterText(r.json.get(filterTy),listFilter[level][filterTy][\"filter\"])\n",
    "                            filterIN=filterIN and new\n",
    "                if not filterIN:\n",
    "                    continue\n",
    "\n",
    "\n",
    "                ###filtering for quantity (not meta data)                        \n",
    "                if \"Quantity\" in listFilter[level].keys():\n",
    "                    r=requests.get(url + \"samples/\" + idSam + \"/quantity\", headers = headers2)\n",
    "                    if BadRequest(r,200):\n",
    "                        r.raise_for_status()\n",
    "                    new=filterQuantity(r.json().get(\"amount\"),\n",
    "                                   listFilter[level][\"Quantity\"][\"filter\"][\"quantity\"],\n",
    "                                   listFilter[level][\"Quantity\"][\"filter\"][\"rule\"])\n",
    "                    #print(\"Quantity \"+format(new))\n",
    "                    filterIN=filterIN and new\n",
    "                if not filterIN:\n",
    "                    continue\n",
    "\n",
    "                ###filtering for meta data fields\n",
    "                r=requests.get(url+\"/samples/\"+idSam+\"/meta\",headers=headers2)\n",
    "                if r.status_code != 200:\n",
    "                    r.raise_for_status()\n",
    "                for meta in r.json().get(\"data\"):\n",
    "                    if meta.get(\"key\") in listFilter[level].keys():\n",
    "                        if listFilter[level][meta.get(\"key\")][\"type\"] == \"DATE\":\n",
    "                            new=filterDate(meta.get(\"value\"),listFilter[level][meta.get(\"key\")][\"filter\"])\n",
    "                        elif listFilter[level][meta.get(\"key\")][\"type\"] == \"TEXT\":\n",
    "                            new=filterText(meta.get(\"value\"),listFilter[level][meta.get(\"key\")][\"filter\"])\n",
    "                        elif listFilter[level][meta.get(\"key\")][\"type\"] == \"SAMPLELINK\":\n",
    "                            new=filterLink(meta.get(\"value\"),\n",
    "                                           listFilter[level][meta.get(\"key\")][\"filter\"][\"list\"],\n",
    "                                           listFilter[level][meta.get(\"key\")][\"filter\"][\"rule\"])\n",
    "                        elif listFilter[level][meta.get(\"key\")][\"type\"] == \"COMBO\":\n",
    "                            new=filterCombo(meta.get(\"value\"),listFilter[level][meta.get(\"key\")][\"filter\"])\n",
    "                        elif listFilter[level][meta.get(\"key\")][\"type\"] == \"CHECKBOX\":\n",
    "                            new=filterCheckbox(meta.get(\"value\"),listFilter[level][meta.get(\"key\")][\"filter\"])\n",
    "                        else:\n",
    "                            raise(listFilter[level][meta.get(\"key\")][\"type\"]+\" not covered\")\n",
    "                        #print(meta.get(\"key\")+\" \"+format(new)+\" \"+format(meta.get(\"value\")))                        \n",
    "                        filterIN=filterIN and new\n",
    "                if not filterIN:\n",
    "                    continue\n",
    "\n",
    "            ###if that entry passed the filter we record the required fields (and the parent sample)\n",
    "\n",
    "            #print(sample+\"-->IN\")\n",
    "            ##adding the name by default\n",
    "            filteredEntries[level][level].append(sample)\n",
    "            \n",
    "            r=requests.get(url+\"/samples/\"+idSam+\"/meta\",headers=headers2)\n",
    "            if r.status_code != 200:\n",
    "                r.raise_for_status()\n",
    "                \n",
    "            ###now adding metadata and data requested by user\n",
    "            for meta in r.json().get(\"data\"):\n",
    "                ##adding the the parent by default\n",
    "                if meta.get(\"sampleDataType\")==\"SAMPLELINK\":\n",
    "                    filteredEntries[level][levelSeq[levelNum]].append(meta.get(\"value\").split(\"|\")[0])\n",
    "                    #filteredEntries[level][\"parent\"].append(meta.get(\"value\").split(\"|\")[0])\n",
    "            if level in types.keys():\n",
    "                for meta in r.json().get(\"data\"):\n",
    "                    ##adding the meta field that the user specified\n",
    "                    if meta.get(\"key\") in types[level][\"meta\"]:\n",
    "                        filteredEntries[level][level+\"_\"+meta.get(\"key\")].append(meta.get(\"value\"))\n",
    "                ##adding the data field that the user specified\n",
    "                if \"description\" in types[level][\"data\"] or \"note\" in types[level][\"data\"]:\n",
    "                    r=requests.get(url+\"/samples/\"+idSam,headers=headers2)\n",
    "                    if r.status_code != 200:\n",
    "                        r.raise_for_status()\n",
    "                    for dataTy in [\"description\",\"note\"]:\n",
    "                        if dataTy in types[level][\"data\"]:\n",
    "                            filteredEntries[level][level+\"_\"+dataTy].append(r.json().get(dataTy))\n",
    "                if \"Quantity\" in types[level][\"data\"]:\n",
    "                    r=requests.get(url+\"/samples/\"+idSam+\"/quantity\",headers=headers2)\n",
    "                    if r.status_code != 200:\n",
    "                        r.raise_for_status()\n",
    "                    filteredEntries[level][level+\"_Quantity\"].append(format(r.json().get(\"amount\"))+r.json().get(\"unit\"))\n",
    "        print(\"we have \"+format(len(filteredEntries[level][level]))+\" remaining\")\n",
    "        # we register the parent samples from that list\n",
    "        if level != \"Site\":\n",
    "            listNextStepKept=filteredEntries[level][levelSeq[levelNum]]\n",
    "        filteredEntries[level][\"df\"]=pd.DataFrame(filteredEntries[level])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e528b51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Library pool skipped\n",
      "Indexed Library skipped\n",
      "Non Indexed Library skipped\n",
      "Extract skipped\n",
      "Skeleton Element skipped\n",
      "Individual skipped\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'df'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-6a572bfd3bf4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mStarting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilteredEntries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"df\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mStarting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'df'"
     ]
    }
   ],
   "source": [
    "        \n",
    "###Now we merge the different data frames obtained for each level into an unique table!\n",
    "Starting=True\n",
    "for level in levelSeq:\n",
    "    if level not in types.keys() and Starting:\n",
    "        print(level+\" skipped\")\n",
    "        continue\n",
    "    if Starting:\n",
    "        out=filteredEntries[level][\"df\"]\n",
    "        Starting=False\n",
    "    else:\n",
    "        out=filteredEntries[level][\"df\"].merge(out,how='inner',on=level)\n",
    "        \n",
    "out.drop_duplicates()        \n",
    "## And we can write!\n",
    "##first some comments to register the filters:\n",
    "jiter=0\n",
    "for level in listFilter.keys():\n",
    "    jiter=jiter+1\n",
    "    f.writelines(\"#\"+format(jiter)+\". filters at: \"+level+\"\\n\")\n",
    "    iter=0\n",
    "    for fifi in listFilter[level].keys():\n",
    "        iter=iter+1\n",
    "        f.writelines(\"#    -\"+format(jiter)+\".\"+format(iter)+\". \"+fifi+\":\"+format(listFilter[level][fifi][\"filter\"])+\"\\n\")\n",
    "f.close()\n",
    "out.to_csv(filename, sep='\\t', na_rep='NA',mode='a')\n",
    "        \n",
    "out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8120177",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Site 164\n",
      "Site_Pictures 67\n",
      "Site_Main geographic region 164\n",
      "Site_Country 164\n",
      "Site_Province / Region 164\n",
      "Site_Locality 164\n",
      "Site_Latitude 164\n",
      "Site_Longitude 164\n",
      "Site_Site type 164\n",
      "Site_description 164\n",
      "Site_Quantity 164\n",
      "Site_note 164\n"
     ]
    }
   ],
   "source": [
    "for key in filteredEntries[\"Site\"].keys():\n",
    "    print(key+\" \"+format(len(filteredEntries[\"Site\"][key])))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "550abd21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filteredEntries[\"Site\"][\"Site_Pictures\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcd7640",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
